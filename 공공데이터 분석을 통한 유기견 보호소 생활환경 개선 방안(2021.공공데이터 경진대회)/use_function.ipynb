{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "d78aa4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category로 바꾸주는 함수\n",
    "\n",
    "def change_category(data):\n",
    "    data['품종'] = data['품종'].astype('category')\n",
    "    data['색상'] = data['색상'].astype('category')\n",
    "    data['성별'] = data['성별'].astype('category')\n",
    "    data['중성화여부'] = data['중성화여부'].astype('category')\n",
    "    data['상태'] = data['상태'].astype('category')\n",
    "    \n",
    "    return data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b91d8608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix 견 / mix 견 아닌거 나눠주는 함수\n",
    "# [0] --> no_mix\n",
    "# [1] --> yes_mix\n",
    "\n",
    "\n",
    "def divide_mix(data):\n",
    "    no_mix = data[data['품종'] != 3]\n",
    "    yes_mix = data[data['품종'] == 3]\n",
    "    \n",
    "    return no_mix, yes_mix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c865b842",
   "metadata": {},
   "source": [
    "### Data Imbalanced Solution\n",
    "---\n",
    "#### Oversampling\n",
    "        \n",
    "    1. OverSampling\n",
    "    \n",
    "        1.1 SMOTE\n",
    "            : Overfitting 이 존재할수도 있다.\n",
    "            \n",
    "        1.2 ADASYN \n",
    "            : SMOTE의 개선된 버전 \n",
    "            \n",
    "    +A. Cost-sensitive learning\n",
    "        \n",
    "            소수의 클래스에 대한 cost 값에 가중치를 더 많이 주어 균형 잡힌 학습이 가능하게 하는 방법\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "71ecdbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번째 --> RandomOverSampler\n",
    "\n",
    "# 2번째 --> SMOTE\n",
    "\n",
    "# 3번째 --> ADASYN\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "# from imblearn.over_sampling import ADASYN\n",
    "\n",
    "\n",
    "def over_sampling(data):\n",
    "    X = data[['품종_mean', '색상', '성별', '체중', '중성화여부', '당시의나이']]\n",
    "    Y = data['상태']\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "\n",
    "    X_resampled_ros, Y_resampled_ros = ros.fit_resample(X,Y)\n",
    "    \n",
    "    X_resampled_smotenc, Y_resampled_smotenc = SMOTENC([0, 1, 2, 4],random_state = 101)\n",
    "    \n",
    "    return [X_resampled_ros, Y_resampled_ros], [X_resampled_smotenc, Y_resampled_smotenc]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0688ecb",
   "metadata": {},
   "source": [
    "### Data Imbalanced Solution\n",
    "----\n",
    "\n",
    "`https://datascienceschool.net/03%20machine%20learning/14.02%20%EB%B9%84%EB%8C%80%EC%B9%AD%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%AC%B8%EC%A0%9C.html`\n",
    "#### Under_Sampling\n",
    "    1. RandomUnderSampler\n",
    "        --> 제일 낮은거랑 동일한 갯수로 모든 것을 Sampling\n",
    "        \n",
    "    2. Tomek's link method\n",
    "        --> 클래스가 다른 두 데이터가 아주 가까이 붙어있으면 토멕링크가 된다. \n",
    "        \n",
    "        \n",
    "    3. Edited Nearest Neighbours\n",
    "       --> 다수 클래스 데이터 중 가장 가까운 k 개의 데이터가 모두 or 다수 클래스가 아니면 삭제하는 방법.\n",
    "       kind_sel = 'all', kind_sel='mode'\n",
    "       \n",
    "    4. Neighbourhood Cleaning Rule\n",
    "       ---> CNN + ENN \n",
    "       ---> Neighbor의 갯수 Tunning\n",
    "       \n",
    "       \n",
    "    \n",
    "       \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "5d001096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under Sampling\n",
    "\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, EditedNearestNeighbours, NeighbourhoodCleaningRule\n",
    "\n",
    "\n",
    "def under_sampling(data):\n",
    "    \n",
    "    \n",
    "    X = data.iloc[:,:-1]\n",
    "    Y = data['상태']\n",
    "    \n",
    "    \n",
    "    X_downsampled_rus, Y_downsampled_rus = RandomUnderSampler().fit_resample(X,Y)\n",
    "    X_downsampled_tomek, Y_downsampled_tomek = TomekLinks().fit_resample(X,Y)\n",
    "    X_downsampled_ENN, Y_downsampled_ENN = EditedNearestNeighbours().fit_resample(X,Y)\n",
    "    X_downsampled_NCR, Y_downsampled_NCR = NeighbourhoodCleaningRule().fit_resample(X,Y)\n",
    "    \n",
    "    return [X_downsampled_rus, Y_downsampled_rus], [X_downsampled_tomek,Y_downsampled_tomek], [X_downsampled_ENN, Y_downsampled_ENN], [X_downsampled_NCR, Y_downsampled_NCR]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5879dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X,Y,test_size = 0.2 ,random_state = 0) : \n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = test_size, random_state = random_state, stratify=Y)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a35f3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model import \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def model_study_function(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # Model import \n",
    "\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors = 7)\n",
    "\n",
    "    rf_clf = RandomForestClassifier(bootstrap = True,\n",
    "     max_depth = 90,\n",
    "     max_features = 2,\n",
    "     min_samples_leaf = 5,\n",
    "     min_samples_split = 12,\n",
    "     n_estimators = 1000)\n",
    "\n",
    "    dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "    ada_clf = AdaBoostClassifier(n_estimators = 100) \n",
    "\n",
    "    mlp_clf = MLPClassifier(solver='lbfgs', random_state = 10,\n",
    "                      hidden_layer_sizes=[100,100], max_iter = 300) # hideen_layer_sizes Tunnig \n",
    "\n",
    "    grd_clf = GradientBoostingClassifier()\n",
    "\n",
    "    gb_clf = GaussianNB() # Tunning 어려움\n",
    "\n",
    "    ex_clf = ExtraTreeClassifier() # Tunning 딱히 불필요 \n",
    "\n",
    "\n",
    "\n",
    "    lr_final = LogisticRegression(C = 0.5)\n",
    "    \n",
    "    \n",
    "    # Model Training \n",
    "\n",
    "    knn_clf.fit(X_train, y_train) \n",
    "    rf_clf.fit(X_train, y_train) \n",
    "    dt_clf.fit(X_train, y_train) \n",
    "    ada_clf.fit(X_train, y_train) \n",
    "    mlp_clf.fit(X_train,y_train)\n",
    "    grd_clf.fit(X_train,y_train)\n",
    "    gb_clf.fit(X_train,y_train)\n",
    "    ex_clf.fit(X_train,y_train)\n",
    "    \n",
    "    print('Train 완료 \\n' )\n",
    "    \n",
    "    # Model Prediction\n",
    "\n",
    "    knn_pred = knn_clf.predict(X_test)\n",
    "    rf_pred = rf_clf.predict(X_test)\n",
    "    dt_pred = dt_clf.predict(X_test)\n",
    "    ada_pred = ada_clf.predict(X_test)\n",
    "    mlp_pred = mlp_clf.predict(X_test)\n",
    "    grd_pred = grd_clf.predict(X_test)\n",
    "    gb_pred = gb_clf.predict(X_test)\n",
    "    ex_pred = ex_clf.predict(X_test)\n",
    "\n",
    "    \n",
    "    knn_score = accuracy_score(y_test, knn_pred)\n",
    "    rf_score = accuracy_score(y_test, rf_pred)\n",
    "    dt_score = accuracy_score(y_test, dt_pred)\n",
    "    ada_score = accuracy_score(y_test, ada_pred)\n",
    "    mlp_score = accuracy_score(y_test, mlp_pred)\n",
    "    grd_score = accuracy_score(y_test, grd_pred)\n",
    "    gb_score = accuracy_score(y_test, gb_pred)  \n",
    "    ex_score = accuracy_score(y_test, ex_pred)               \n",
    "                   \n",
    "    \n",
    "    print('KNN 정확도 : {0:.4f}'.format(accuracy_score(y_test, knn_pred)))\n",
    "    print('랜덤 포레스트 정확도 : {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "    print('결정 트리 정확도 : {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "    print('에이다부스트 정확도 : {0:.4f}'.format(accuracy_score(y_test, ada_pred)))\n",
    "    print('MLPClassfier 정확도 : {0:.4f}'.format(accuracy_score(y_test, mlp_pred)))\n",
    "    print('GradientBoostingClassifer : {0:.4f}'.format(accuracy_score(y_test, grd_pred)))\n",
    "    print('GaussianNB 정확도 : {0:.4f}'.format(accuracy_score(y_test, gb_pred)))\n",
    "    print('ExtraTreeclassifer 정확도 : {0:.4f}'.format(accuracy_score(y_test, ex_pred)))\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "    \n",
    "                               \n",
    "    result_list = [knn_score, rf_score, dt_score, ada_score, mlp_score, grd_score, gb_score, ex_score]\n",
    "    pred_list = [knn_pred, rf_pred, dt_pred, ada_pred, mlp_pred, grd_pred, gb_pred, ex_pred]\n",
    "                               \n",
    "    \n",
    "    top5_list = pd.DataFrame(result_list).rank(ascending=False).sort_values(by=0)[:5].index\n",
    "\n",
    "\n",
    "                            \n",
    "                               \n",
    "                               \n",
    "    \n",
    "    pred = np.array([pred_list[top5_list[0]],pred_list[top5_list[1]], pred_list[top5_list[2]], pred_list[top5_list[3]], pred_list[top5_list[4]]])\n",
    "                               \n",
    "                               \n",
    "    pred = np.transpose(pred)\n",
    "    \n",
    "    lr_final.fit(pred, y_test)\n",
    "    final = lr_final.predict(pred)\n",
    "\n",
    "    print('최종 메타 모델의 예측 정확도 : {0:.4f}'.format(accuracy_score(y_test, final)))\n",
    "    print(\"=\"* 30)\n",
    "    \n",
    "    \n",
    "\n",
    "    print('최종 모델의 f1_score : ',f1_score(y_test, final) )\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    y_train_pred = cross_val_predict(lr_final, X_train, y_train, cv = 3)\n",
    "    cf = confusion_matrix(y_train, y_train_pred)\n",
    "    print('최종 모델의 Confusion Matrix : \\n', cf)\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    return print(\"완료\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea99938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
