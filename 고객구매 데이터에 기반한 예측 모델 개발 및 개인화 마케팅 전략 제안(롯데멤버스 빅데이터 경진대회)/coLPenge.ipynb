{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GchKnrGzSzK-"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vilD19QJUqed"
   },
   "source": [
    "# DataFrame 만들기\n",
    "  * products.csv\n",
    "  * services.csv\n",
    "  * final.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8b592340"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "be9d90d7"
   },
   "outputs": [],
   "source": [
    "csv_lists = os.listdir('/content/drive/MyDrive/Project/lotte/DATA')\n",
    "csv_lists = csv_lists[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fca967ba"
   },
   "outputs": [],
   "source": [
    "csv_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "143c887d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demo = pd.read_csv('./data/'+csv_lists[0]) # demo 와 coporation에 merge 됨\n",
    "buy = pd.read_csv('./data/'+csv_lists[1])\n",
    "coporation= pd.read_csv('./data/'+csv_lists[2])  # 제휴사\n",
    "partner = pd.read_csv('./data/'+csv_lists[3])  # buy 에 merge 됨  # 유통사\n",
    "stores= pd.read_csv('./data/'+csv_lists[4])   # 점포\n",
    "Lpay = pd.read_csv('./data/'+csv_lists[5])  # Lpay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "913c9bec"
   },
   "outputs": [],
   "source": [
    "demo.columns = ['고객번호','성별', '연령대', '거주지대분류코드']\n",
    "buy.columns = ['고객번호', '영수증번호', '채널구분(1:오프, 2:온)', '제휴사(유통사만 A01~06)', '점포코드', '상품코드', '구매일자', '구매시간', '구매금액' , '구매수량']\n",
    "coporation.columns = ['고객번호', '영수증번호', '제휴사(B~E:숙박/엔터/F&B/렌탈)', '점포코드', '채널구분(1:오프, 2:온)', '이용일자', '방문일자', '이용시간', '이용금액']\n",
    "partner.columns = ['상품코드', '소분류명', '중분류명', '대분류명']\n",
    "stores.columns = ['점포코드', '제휴사', '점포지역대분류', '점포지역중분류']\n",
    "Lpay.columns = ['고객번호', '영수증번호', '제휴사', '채널구분(1:오프, 2:온)', '이용일자', '이용시간', '이용금액']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5e298dfb"
   },
   "source": [
    "## products DataFrame 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ad834c2"
   },
   "outputs": [],
   "source": [
    "buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50b25fa8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "partner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91f7dfda"
   },
   "outputs": [],
   "source": [
    "buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cbdc2530"
   },
   "outputs": [],
   "source": [
    "product = pd.merge(buy, partner, on = '상품코드', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4e54e63"
   },
   "outputs": [],
   "source": [
    "product_1 = product[product['채널구분(1:오프, 2:온)']==1]\n",
    "product_2 = product[product['채널구분(1:오프, 2:온)']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85a4de6c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(product_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c63c8dc4"
   },
   "outputs": [],
   "source": [
    "stores_product = stores[(stores['제휴사']=='A01') | (stores['제휴사']=='A02') | (stores['제휴사']=='A03') | (stores['제휴사']=='A04') | (stores['제휴사']=='A05') | (stores['제휴사']=='A06')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26b68f18",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "product_1 = pd.merge(product_1, stores_product, on = '점포코드', how = 'left')\n",
    "len(product_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9539e76",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "product_1 = product_1[['고객번호', '영수증번호', '채널구분(1:오프, 2:온)', '제휴사(유통사만 A01~06)', '점포코드', '상품코드',\n",
    "       '구매일자', '구매시간', '구매금액', '구매수량', '소분류명', '중분류명', '대분류명',\n",
    "       '점포지역대분류', '점포지역중분류']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e09ddabe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "product_2['점포지역대분류'] = np.nan\n",
    "product_2['점포지역중분류'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ccb45b9"
   },
   "outputs": [],
   "source": [
    "product = pd.concat([product_1, product_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "696760fd"
   },
   "outputs": [],
   "source": [
    "product = pd.merge(product, demo, on = '고객번호', how = 'left')\n",
    "product = product.dropna(subset=['영수증번호'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16df429f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Lpay_product = Lpay[(Lpay['제휴사']=='A01') | (Lpay['제휴사']=='A02') | (Lpay['제휴사']=='A03') | (Lpay['제휴사']=='A04') | (Lpay['제휴사']=='A05') | (Lpay['제휴사']=='A06')]\n",
    "Lpay_product.columns = ['고객번호', '영수증번호', '제휴사(유통사만 A01~06)', '채널구분(1:오프, 2:온)', '구매일자', '구매시간', '구매금액']\n",
    "Lpay_product['구매금액'] = Lpay_product['구매금액'].astype('float64')\n",
    "Lpay_product = Lpay_product[['고객번호', '제휴사(유통사만 A01~06)', '채널구분(1:오프, 2:온)', '구매일자', '구매시간', '구매금액']]\n",
    "Lpay_product                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2ca9bf4"
   },
   "outputs": [],
   "source": [
    "Lpay_client = Lpay_product['고객번호'].value_counts().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5422501"
   },
   "outputs": [],
   "source": [
    "len(Lpay_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bca61df8"
   },
   "outputs": [],
   "source": [
    "product = product.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2cd7c88"
   },
   "outputs": [],
   "source": [
    "product['Lpay_client']=0\n",
    "for i in tqdm(range(len(Lpay_client))) : \n",
    "    product.iloc[product[product['고객번호'] == Lpay_client[i]].index,-1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cf985e15"
   },
   "outputs": [],
   "source": [
    "product = product[['영수증번호', '고객번호', '성별', '연령대', '거주지대분류코드',  '상품코드', '대분류명', '중분류명', '소분류명', \n",
    "       '구매일자', '구매시간',  '구매수량', '구매금액',  '제휴사(유통사만 A01~06)','점포코드', '점포지역대분류',\n",
    "       '점포지역중분류',  '채널구분(1:오프, 2:온)', 'Lpay_client']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "da534ae9"
   },
   "outputs": [],
   "source": [
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ac760cf"
   },
   "outputs": [],
   "source": [
    "product['채널구분(1:오프, 2:온)'] = product['채널구분(1:오프, 2:온)'].astype(int)\n",
    "Lpay_product['채널구분(1:오프, 2:온)'] = Lpay_product['채널구분(1:오프, 2:온)'].astype(int)\n",
    "\n",
    "product['구매일자'] = product['구매일자'].astype(int)\n",
    "Lpay_product['구매일자'] = Lpay_product['구매일자'].astype(int)\n",
    "\n",
    "product['구매시간'] = product['구매시간'].astype(int)\n",
    "Lpay_product['구매시간'] = Lpay_product['구매시간'].astype(int)\n",
    "\n",
    "product['구매금액'] = product['구매금액'].astype(float)\n",
    "Lpay_product['구매금액'] = Lpay_product['구매금액'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9c665d63"
   },
   "outputs": [],
   "source": [
    "product.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dc0d92d3"
   },
   "outputs": [],
   "source": [
    "Lpay_product.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f74354aa"
   },
   "outputs": [],
   "source": [
    "product_Lpay = product[product['Lpay_client']==1]\n",
    "product_n_Lpay = product[product['Lpay_client']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e540cf8e"
   },
   "outputs": [],
   "source": [
    "len(product_Lpay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21f85fdb"
   },
   "outputs": [],
   "source": [
    "product_Lpay['Lpay'] = 0\n",
    "product_n_Lpay['Lpay'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65220a0f"
   },
   "outputs": [],
   "source": [
    "Lpay_index = []\n",
    "for k in tqdm(range(len(Lpay_client))) : \n",
    "    tt = product_Lpay[product_Lpay['고객번호']==Lpay_client[k]][['고객번호', '제휴사(유통사만 A01~06)', '채널구분(1:오프, 2:온)', '구매일자', '구매시간', '구매금액']]\n",
    "    qq = Lpay_product[Lpay_product['고객번호']==Lpay_client[k]]\n",
    "\n",
    "    qq_list = []\n",
    "    for i in range(len(qq)) : \n",
    "        qq_list.append(qq.iloc[i,:].tolist())\n",
    "    for j in range(len(tt)) : \n",
    "        if tt.iloc[j,:].tolist() in qq_list : \n",
    "            Lpay_index.append(tt.index[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42a3f572"
   },
   "outputs": [],
   "source": [
    "product_Lpay.loc[Lpay_index, 'Lpay'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10d1af43"
   },
   "outputs": [],
   "source": [
    "product_Lpay['Lpay'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e168bd1b"
   },
   "outputs": [],
   "source": [
    "product = pd.concat([product_Lpay, product_n_Lpay], axis = 0)\n",
    "product = product.sort_values(['구매일자', '구매시간'])\n",
    "product = product.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c50ee85a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "920344af"
   },
   "outputs": [],
   "source": [
    "product.to_csv('./data/products.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2d8dd403"
   },
   "outputs": [],
   "source": [
    "pd.read_csv('./data/products.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70cf463f"
   },
   "source": [
    "## services DataFrame 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbd97acd"
   },
   "outputs": [],
   "source": [
    "service = pd.merge(coporation, demo, on = '고객번호', how = 'left')\n",
    "service = service.dropna(subset=['영수증번호'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dc28c38"
   },
   "outputs": [],
   "source": [
    "service_1 = service[service['채널구분(1:오프, 2:온)']==1.0]\n",
    "service_2 = service[service['채널구분(1:오프, 2:온)']==2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4b92108"
   },
   "outputs": [],
   "source": [
    "len(service_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16f0c9dd"
   },
   "outputs": [],
   "source": [
    "service_1 = pd.merge(service_1, stores, on = '점포코드', how = 'left')\n",
    "service_1 = service_1.dropna(subset=['고객번호'])\n",
    "len(service_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fef4986",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "service = pd.concat([service_1, service_2], axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9a3b8257"
   },
   "outputs": [],
   "source": [
    "service = service.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9b6efa74"
   },
   "outputs": [],
   "source": [
    "Lpay_product_index = Lpay[(Lpay['제휴사']=='A01') | (Lpay['제휴사']=='A02') | (Lpay['제휴사']=='A03') | (Lpay['제휴사']=='A04') | (Lpay['제휴사']=='A05') | (Lpay['제휴사']=='A06')].index\n",
    "Lpay_service = Lpay.drop(Lpay_product_index)\n",
    "Lpay_service.columns = ['고객번호', '영수증번호', '제휴사(B~E:숙박/엔터/F&B/렌탈)', '채널구분(1:오프, 2:온)', '이용일자', '이용시간', '이용금액']\n",
    "Lpay_service['이용금액'] = Lpay_service['이용금액'].astype('float64')\n",
    "Lpay_service = Lpay_service[['고객번호', '제휴사(B~E:숙박/엔터/F&B/렌탈)', '채널구분(1:오프, 2:온)', '이용일자', '이용시간', '이용금액']]\n",
    "Lpay_service  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "addf9b2d"
   },
   "outputs": [],
   "source": [
    "Lpay_service_client = Lpay_service['고객번호'].value_counts().index.tolist()\n",
    "len(Lpay_service_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fb49cafe"
   },
   "outputs": [],
   "source": [
    "service['Lpay_client'] = 0\n",
    "for i in tqdm(range(len(Lpay_service_client))) : \n",
    "    service.iloc[service[service['고객번호'] == Lpay_service_client[i]].index,-1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1c4defa"
   },
   "outputs": [],
   "source": [
    "service = service[['영수증번호', '고객번호', '성별', '연령대', '거주지대분류코드', \n",
    "       '방문일자', '이용일자', '이용시간', '이용금액', '제휴사(B~E:숙박/엔터/F&B/렌탈)', '점포코드', '점포지역대분류', '점포지역중분류',\n",
    "        '채널구분(1:오프, 2:온)','Lpay_client']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6ffcbed"
   },
   "outputs": [],
   "source": [
    "service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "829f9a0f"
   },
   "outputs": [],
   "source": [
    "service['채널구분(1:오프, 2:온)'] = service['채널구분(1:오프, 2:온)'].astype(int)\n",
    "Lpay_service['채널구분(1:오프, 2:온)'] = Lpay_service['채널구분(1:오프, 2:온)'].astype(int)\n",
    "\n",
    "service['이용일자'] = service['이용일자'].astype(int)\n",
    "Lpay_service['이용일자'] = Lpay_service['이용일자'].astype(int)\n",
    "\n",
    "service['이용시간'] = service['이용시간'].astype(int)\n",
    "Lpay_service['이용시간'] = Lpay_service['이용시간'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7b1c731b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "service.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5907399"
   },
   "outputs": [],
   "source": [
    "Lpay_service.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2298771d"
   },
   "outputs": [],
   "source": [
    "service_Lpay = service[service['Lpay_client']==1]\n",
    "service_n_Lpay = service[service['Lpay_client']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d2c9c0ee"
   },
   "outputs": [],
   "source": [
    "len(service_Lpay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "798ffaa9"
   },
   "outputs": [],
   "source": [
    "service_Lpay['Lpay'] = 0\n",
    "service_n_Lpay['Lpay'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "873e581b"
   },
   "outputs": [],
   "source": [
    "service_Lpay_index = []\n",
    "for k in tqdm(range(len(Lpay_service_client))) : \n",
    "    tt = service_Lpay[service_Lpay['고객번호']==Lpay_service_client[k]][['고객번호', '제휴사(B~E:숙박/엔터/F&B/렌탈)', '채널구분(1:오프, 2:온)', '이용일자', '이용시간', '이용금액']]\n",
    "    qq = Lpay_service[Lpay_service['고객번호']==Lpay_service_client[k]]\n",
    "\n",
    "    qq_list = []\n",
    "    for i in range(len(qq)) : \n",
    "        qq_list.append(qq.iloc[i,:].tolist())\n",
    "    for j in range(len(tt)) : \n",
    "        if tt.iloc[j,:].tolist() in qq_list : \n",
    "            service_Lpay_index.append(tt.index[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eb5888d"
   },
   "outputs": [],
   "source": [
    "service_Lpay.loc[service_Lpay_index, 'Lpay'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3d1c78cf"
   },
   "outputs": [],
   "source": [
    "service_Lpay['Lpay'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "838e5525"
   },
   "outputs": [],
   "source": [
    "service = pd.concat([service_Lpay, service_n_Lpay], axis = 0)\n",
    "service = service.sort_values(['이용일자', '이용시간'])\n",
    "service = service.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0297208b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3313bf11"
   },
   "outputs": [],
   "source": [
    "service.to_csv('./data/services.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0210b9d1"
   },
   "outputs": [],
   "source": [
    "pd.read_csv('./data/services.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udNt_l7rU4wy"
   },
   "source": [
    "## final DataFrame 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWqTdJDHU7wc"
   },
   "outputs": [],
   "source": [
    "product = pd.read_csv('./data/products.csv')\n",
    "service = pd.read_csv('./data/services.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Myz0Ge1PU71j"
   },
   "outputs": [],
   "source": [
    "product = product[['고객번호','성별','연령대','거주지대분류코드','구매일자','구매시간','구매금액','제휴사(유통사만 A01~06)','점포코드','점포지역대분류','채널구분(1:오프, 2:온)','Lpay']]\n",
    "service = service[['고객번호','성별','연령대','거주지대분류코드','이용일자','이용시간','이용금액','제휴사(B~E:숙박/엔터/F&B/렌탈)','점포코드','점포지역대분류','채널구분(1:오프, 2:온)','Lpay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqjO0T5jU731"
   },
   "outputs": [],
   "source": [
    "product.rename(columns={'제휴사(유통사만 A01~06)':'제휴사'},inplace=True)\n",
    "service.rename(columns={'이용일자':'구매일자','이용시간':'구매시간','이용금액':'구매금액','제휴사(B~E:숙박/엔터/F&B/렌탈)':'제휴사'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([product,service],axis=0)\n",
    "data = data.reset_index()\n",
    "data.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['temp'] = data.groupby(['고객번호'])['Lpay'].transform('sum') \n",
    "data['Lpay_client'] = data['temp'].apply(lambda x: 1 if x > 0 else 0)  \n",
    "data.drop('temp', axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./data/final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcC-eQZGVBYJ"
   },
   "source": [
    "# 고객 생애 가치(Customer Lifetime Value:CLTV) 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJsMCrV4KkAr"
   },
   "outputs": [],
   "source": [
    "!pip install lifetimes\n",
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKJgAkj-IGfG"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3Dp8QeWIzUl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "mpl.rc('font', family='Malgun Gothic') # 폰트 설정\n",
    "mpl.rc('axes', unicode_minus=False) # 유니코드에서 음수 부호 설정\n",
    "\n",
    "# 차트 스타일 설정\n",
    "sns.set(font=\"Malgun Gothic\", rc={\"axes.unicode_minus\":False}, style='darkgrid')\n",
    "plt.rc(\"figure\", figsize=(10,8))\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pja66yGeG3ji"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "product = pd.read_csv('/content/gdrive/MyDrive/Project/lotte/data/final.csv')\n",
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkupNq6PK43M"
   },
   "outputs": [],
   "source": [
    "# 작성날짜 datetime으로 변환\n",
    "product['구매일자'] = product['구매일자'].astype('str')\n",
    "product['구매일자'] = pd.to_datetime(product['구매일자'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UglO_fq5QjJT"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lifetimes import BetaGeoFitter\n",
    "from lifetimes import GammaGammaFitter\n",
    "from lifetimes.plotting import plot_period_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrnvvcpPi3oj"
   },
   "outputs": [],
   "source": [
    "from lifetimes.utils import summary_data_from_transaction_data\n",
    "\n",
    "summary = summary_data_from_transaction_data(product, '고객번호', '구매일자','구매금액', freq='D', observation_period_end='2021-12-31')\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_UMGKjK03kU"
   },
   "outputs": [],
   "source": [
    "len(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bpqn-IukKC8s"
   },
   "outputs": [],
   "source": [
    "summary.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4jy-1ZvjA0q"
   },
   "outputs": [],
   "source": [
    "# BG-NBD 모델 생성 \n",
    "bgf = BetaGeoFitter(penalizer_coef=0.001) #  0.001에서 0.1 정도가 일반적!\n",
    "bgf.fit(summary['frequency'], summary['recency'], summary['T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AAsHbv7aIuK"
   },
   "outputs": [],
   "source": [
    "from lifetimes.plotting import plot_frequency_recency_matrix\n",
    "\n",
    "plot_frequency_recency_matrix(bgf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRrW8yHQVXpO"
   },
   "outputs": [],
   "source": [
    "# 모델 적합성 평가\n",
    "from lifetimes.plotting import plot_period_transactions\n",
    "\n",
    "plot_period_transactions(bgf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q9P_yAHFjALZ"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 분할\n",
    "# 새로운 데이터에 대해 어떻게 작동하는지 테스트하기 위해\n",
    "\n",
    "from lifetimes.utils import calibration_and_holdout_data\n",
    "\n",
    "summary_cal_holdout = calibration_and_holdout_data(product, '고객번호', '구매일자',\n",
    "                                        calibration_period_end='2021-09-01',\n",
    "                                        observation_period_end='2021-12-31' )   \n",
    "summary_cal_holdout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ltSyWSFfRs2"
   },
   "outputs": [],
   "source": [
    "from lifetimes.plotting import plot_calibration_purchases_vs_holdout_purchases\n",
    "\n",
    "bgf.fit(summary_cal_holdout['frequency_cal'], summary_cal_holdout['recency_cal'], summary_cal_holdout['T_cal'])\n",
    "plot_calibration_purchases_vs_holdout_purchases(bgf, summary_cal_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "giycxQW1fRvf"
   },
   "outputs": [],
   "source": [
    "# 고객 예측\n",
    "t = 10 #predict purchases in 10 periods\n",
    "individual = summary.iloc[20]\n",
    "# The below function is an alias to `bfg.conditional_expected_number_of_purchases_up_to_time`\n",
    "bgf.predict(t, individual['frequency'], individual['recency'], individual['T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-umTIeJfRyZ"
   },
   "outputs": [],
   "source": [
    "# 고객의 재방문 확률 시계열\n",
    "from lifetimes.plotting import plot_history_alive\n",
    "\n",
    "id = 'M000136117' ## 고객 한명당 확률 보여줌\n",
    "days_since_birth = 200\n",
    "sp_trans = product.loc[product['고객번호'] == id]\n",
    "plot_history_alive(bgf, days_since_birth, sp_trans, '구매일자')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAMMA-GAMMA 모델 생성 & 고객의 평생 가치(CLV) 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNE_TwgOmpF7"
   },
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-u3avlPl9FW"
   },
   "outputs": [],
   "source": [
    "summary = summary[summary['frequency']>0]\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPMfulB4mtLn"
   },
   "outputs": [],
   "source": [
    "summary[['monetary_value', 'frequency']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUkbM1zem95k"
   },
   "outputs": [],
   "source": [
    "from lifetimes import GammaGammaFitter\n",
    "\n",
    "ggf = GammaGammaFitter(penalizer_coef = 0)\n",
    "ggf.fit(summary['frequency'],\n",
    "        summary['monetary_value'])\n",
    "print(ggf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5f33t4D0nEE5"
   },
   "outputs": [],
   "source": [
    "print(ggf.conditional_expected_average_profit(\n",
    "        summary['frequency'],\n",
    "        summary['monetary_value']\n",
    "    ).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7NYUI6kTnIek"
   },
   "outputs": [],
   "source": [
    "print(\"Expected conditional average profit: %s, Average profit: %s\" % (\n",
    "    ggf.conditional_expected_average_profit(\n",
    "        summary['frequency'],\n",
    "        summary['monetary_value']\n",
    "    ).mean(),\n",
    "    summary[summary['frequency']>0]['monetary_value'].mean()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "227lVWvHnOCH"
   },
   "outputs": [],
   "source": [
    "# refit the BG model to the summary_with_money_value dataset\n",
    "#bgf.fit(summary['frequency'], summary['recency'], summary['T'])\n",
    "\n",
    "print(ggf.customer_lifetime_value(\n",
    "    bgf, #the model to use to predict the number of future transactions\n",
    "    summary['frequency'],\n",
    "    summary['recency'],\n",
    "    summary['T'],\n",
    "    summary['monetary_value'],\n",
    "    time=7, # days\n",
    "    freq='D',\n",
    "    discount_rate=0.01 # monthly discount rate ~ 12.7% annually\n",
    ").head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecUqxWTsnfoi"
   },
   "outputs": [],
   "source": [
    "cltv = ggf.customer_lifetime_value(\n",
    "    bgf, #the model to use to predict the number of future transactions\n",
    "    summary['frequency'],\n",
    "    summary['recency'],\n",
    "    summary['T'],\n",
    "    summary['monetary_value'],\n",
    "    time=7, # days\n",
    "    freq='D',\n",
    "    discount_rate=0.01) # monthly discount rate ~ 12.7% annually\n",
    "cltv = cltv.reset_index()\n",
    "cltv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7ZkRtdtnx9h"
   },
   "outputs": [],
   "source": [
    "cltv_final = summary.merge(cltv, on=\"고객번호\", how=\"left\")\n",
    "\n",
    "cltv_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DtbQokRPnx_9"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1)) \n",
    "#score between 0-1 ,1 is best 0 is worst. You can change by your wish, if you want you can score between 0-100 .\n",
    "scaler.fit(cltv_final[[\"clv\"]])\n",
    "cltv_final[\"scaled_clv\"] = scaler.transform(cltv_final[[\"clv\"]])\n",
    "cltv_final.sort_values(by=[\"scaled_clv\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTzX-jKqJZeP"
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IX62iNwnzvK"
   },
   "outputs": [],
   "source": [
    "cltv_final = cltv_final.sort_values(by=[\"clv\"], ascending=False)\n",
    "cltv_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RkpAABIoYE2"
   },
   "outputs": [],
   "source": [
    "cltv_final.to_csv('/content/gdrive/MyDrive/Lpoint_Lpay/data/final_cltv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1LSgwgFIeND"
   },
   "outputs": [],
   "source": [
    "cltv_final['scaled_clv'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEK0P3ZkVfpj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cRDLNTaWH2E"
   },
   "source": [
    "# 고객군 군집화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "531d9174"
   },
   "outputs": [],
   "source": [
    "#라이브러리 로드\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "import requests \n",
    "import json \n",
    "import xmltodict\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import scipy.cluster.hierarchy as shc\n",
    "%cd /Users/diekim/Desktop/ETC/LPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17f8619b"
   },
   "outputs": [],
   "source": [
    "#함수 정의\n",
    "### 실루엣 계수 시각화 함수: 여러개의 클러스터링 갯수를 List로 입력 받아 각각의 실루엣 계수를 면적으로 시각화한 함수 작성\n",
    "def visualize_silhouette(cluster_lists, X_features): \n",
    "    \n",
    "    from sklearn.datasets import make_blobs\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "    import math\n",
    "    \n",
    "    # 입력값으로 클러스터링 갯수들을 리스트로 받아서, 각 갯수별로 클러스터링을 적용하고 실루엣 개수를 구함\n",
    "    n_cols = len(cluster_lists)\n",
    "    \n",
    "    # plt.subplots()으로 리스트에 기재된 클러스터링 수만큼의 sub figures를 가지는 axs 생성 \n",
    "    fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)\n",
    "    \n",
    "    # 리스트에 기재된 클러스터링 갯수들을 차례로 iteration 수행하면서 실루엣 개수 시각화\n",
    "    for ind, n_cluster in enumerate(cluster_lists):\n",
    "        \n",
    "        # KMeans 클러스터링 수행하고, 실루엣 스코어와 개별 데이터의 실루엣 값 계산. \n",
    "        clusterer = KMeans(n_clusters = n_cluster, max_iter=500, random_state=0)\n",
    "        cluster_labels = clusterer.fit_predict(X_features)\n",
    "        \n",
    "        sil_avg = silhouette_score(X_features, cluster_labels)\n",
    "        sil_values = silhouette_samples(X_features, cluster_labels)\n",
    "        \n",
    "        y_lower = 10\n",
    "        axs[ind].set_title('Number of Cluster : '+ str(n_cluster)+'\\n' \\\n",
    "                          'Silhouette Score :' + str(round(sil_avg,3)) )\n",
    "        axs[ind].set_xlabel(\"The silhouette coefficient values\")\n",
    "        axs[ind].set_ylabel(\"Cluster label\")\n",
    "        axs[ind].set_xlim([-0.1, 1])\n",
    "        axs[ind].set_ylim([0, len(X_features) + (n_cluster + 1) * 10])\n",
    "        axs[ind].set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        axs[ind].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        \n",
    "        # 클러스터링 갯수별로 fill_betweenx( )형태의 막대 그래프 표현. \n",
    "        for i in range(n_cluster):\n",
    "            ith_cluster_sil_values = sil_values[cluster_labels==i]\n",
    "            ith_cluster_sil_values.sort()\n",
    "            \n",
    "            size_cluster_i = ith_cluster_sil_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "            \n",
    "            color = cm.nipy_spectral(float(i) / n_cluster)\n",
    "            axs[ind].fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_sil_values, \\\n",
    "                                facecolor=color, edgecolor=color, alpha=0.7)\n",
    "            axs[ind].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "            y_lower = y_upper + 10\n",
    "            \n",
    "        axs[ind].axvline(x=sil_avg, color=\"red\", linestyle=\"--\")\n",
    "        \n",
    "### 군집별 시각화 함수: 여러개의 클러스터링 갯수를 List로 입력 받아 각각의 클러스터링 결과를 시각화 \n",
    "def visualize_kmeans_plot_multi(cluster_lists, X_features):\n",
    "    \n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.decomposition import PCA\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # plt.subplots()으로 리스트에 기재된 클러스터링 만큼의 sub figures를 가지는 axs 생성 \n",
    "    n_cols = len(cluster_lists)\n",
    "    fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)\n",
    "    \n",
    "    # 입력 데이터의 FEATURE가 여러개일 경우 2차원 데이터 시각화가 어려우므로 PCA 변환하여 2차원 시각화\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_transformed = pca.fit_transform(X_features)\n",
    "    dataframe = pd.DataFrame(pca_transformed, columns=['PCA1','PCA2'])\n",
    "    \n",
    "     # 리스트에 기재된 클러스터링 갯수들을 차례로 iteration 수행하면서 KMeans 클러스터링 수행하고 시각화\n",
    "    for ind, n_cluster in enumerate(cluster_lists):\n",
    "        \n",
    "        # KMeans 클러스터링으로 클러스터링 결과를 dataframe에 저장. \n",
    "        clusterer = KMeans(n_clusters = n_cluster, max_iter=500, random_state=0)\n",
    "        cluster_labels = clusterer.fit_predict(pca_transformed)\n",
    "        dataframe['cluster']=cluster_labels\n",
    "        \n",
    "        unique_labels = np.unique(clusterer.labels_)\n",
    "        markers=['o', 's', '^', 'x', '*','d','+']\n",
    "       \n",
    "        # 클러스터링 결과값 별로 scatter plot 으로 시각화\n",
    "        for label in unique_labels:\n",
    "            label_df = dataframe[dataframe['cluster']==label]\n",
    "            if label == -1:\n",
    "                cluster_legend = 'Noise'\n",
    "            else :\n",
    "                cluster_legend = 'Cluster '+str(label)           \n",
    "            axs[ind].scatter(x=label_df['PCA1'], y=label_df['PCA2'], s=70,\\\n",
    "                        edgecolor='k', marker=markers[label], label=cluster_legend)\n",
    "\n",
    "        axs[ind].set_title('Number of Cluster : '+ str(n_cluster))    \n",
    "        axs[ind].legend(loc='upper right')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aff99eb8"
   },
   "outputs": [],
   "source": [
    "#데이터 정리(only 재방문 유저)\n",
    "final = pd.read_csv('final.csv').iloc[:, 1:]\n",
    "cltv = pd.read_csv('final_cltv.csv').iloc[:, 1:]\n",
    "\n",
    "df = pd.merge(final, cltv, on='고객번호', how='left')\n",
    "df = df.dropna(subset=['frequency'])\n",
    "\n",
    "df['구매일자'] = df['구매일자'].astype('str')\n",
    "df['구매일자'] = pd.to_datetime(df['구매일자'])\n",
    "\n",
    "df['d_min'] = df.groupby('고객번호')['구매일자'].transform('min')\n",
    "df['d_max'] = df.groupby('고객번호')['구매일자'].transform('max')\n",
    "\n",
    "df['R'] = df['d_max'] - df['d_min']\n",
    "df['R'] = df['R'].apply(lambda x: x.days)\n",
    "\n",
    "def m1(x):\n",
    "    if x['Lpay']==1:\n",
    "        return x['구매금액']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def m2(x):\n",
    "    if x['Lpay']==0:\n",
    "        return x['구매금액']\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['M1'] = df.apply(m1, axis=1)\n",
    "df['M2'] = df.apply(m2, axis=1) \n",
    "\n",
    "client_df = df.groupby('고객번호').agg({'R':'mean',\n",
    "                                      #'구매일자': 'count',\n",
    "                                      '구매금액': 'mean',\n",
    "                                      'M1': 'mean',\n",
    "                                      'M2': 'mean',\n",
    "                                      'Lpay': 'sum',\n",
    "                                      'Lpay_client': 'mean'}).reset_index()\n",
    "\n",
    "client_df = pd.merge(client_df, \n",
    "                     df[['고객번호', 'frequency', '성별', '연령대', '거주지대분류코드']],\n",
    "                     on='고객번호', \n",
    "                     how='left').drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "client_df.columns = ['고객번호', 'R', 'M', 'M1', 'M2', 'Lpay', 'Lpay_client', 'F', '성별', '연령대', '거주지']\n",
    "\n",
    "temp = df.groupby(['고객번호', '제휴사'])['구매금액'].sum().reset_index()\n",
    "temp2 = temp.groupby('고객번호')['구매금액'].max().reset_index()\n",
    "temp3 = pd.merge(temp, temp2, on=['고객번호', '구매금액'], how='inner')\n",
    "\n",
    "client_df = pd.merge(client_df, temp3[['고객번호', '제휴사']], on='고객번호')\n",
    "client_df.to_csv('final_client_df.csv', encoding='utf-8-sig', index=False)\n",
    "client_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6b32b219"
   },
   "outputs": [],
   "source": [
    "#데이터 정리(for 클러스터링)\n",
    "df = pd.read_csv('final_client_df.csv')\n",
    "\n",
    "en = LabelEncoder()\n",
    "df['연령대'] = en.fit_transform(df['연령대'])\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "df['연령대'] = pd.DataFrame(sc.fit_transform(df[['연령대']]), columns=['연령대'])\n",
    "\n",
    "df['성별'].replace({'남성': 1, '여성': 0}, inplace=True)\n",
    "df_encoded = pd.get_dummies(df[['거주지', '제휴사']])\n",
    "\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "df.index = df['고객번호']\n",
    "df.drop(['고객번호', '거주지', '제휴사'], axis=1, inplace=True)\n",
    "\n",
    "features = ['R', 'F', 'M1', 'M2', 'Lpay', '성별', '연령대']\n",
    "df = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3a1cd351"
   },
   "outputs": [],
   "source": [
    "# 클러스터링\n",
    "##1. 원데이터\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "X_features = df.values\n",
    "\n",
    "# KMeans\n",
    "kmeans = KMeans(n_clusters=4, random_state=0)\n",
    "labels = kmeans.fit_predict(X_features)\n",
    "df[\"cluster_label\"] = labels\n",
    "\n",
    "# 실루엣 스코어\n",
    "silhouette_kmeans = silhouette_score(X_features, labels)\n",
    "print(f\"실루엣 스코어: {silhouette_kmeans:.3f}\")\n",
    "\n",
    "visualize_silhouette([3,4,5], X_features)\n",
    "visualize_kmeans_plot_multi([3,4,5], X_features)\n",
    "\n",
    "##2. StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# StandardScaler\n",
    "X_features = df.values\n",
    "X_features_scaled = StandardScaler().fit_transform(X_features)\n",
    "\n",
    "# KMeans\n",
    "kmeans = KMeans(n_clusters=4, random_state=0)\n",
    "labels = kmeans.fit_predict(X_features_scaled)\n",
    "df[\"cluster_label\"] = labels\n",
    "\n",
    "# 실루엣 스코어\n",
    "silhouette_kmeans = silhouette_score(X_features_scaled, labels)\n",
    "print(f\"실루엣 스코어: {silhouette_kmeans:.3f}\")\n",
    "\n",
    "visualize_silhouette([3,4,5], X_features_scaled)\n",
    "visualize_kmeans_plot_multi([3,4,5], X_features_scaled)\n",
    "\n",
    "##3. 로그변환+표준화X\n",
    "\n",
    "# 로그 변환\n",
    "df['R_log'] = np.log1p(df['R'])\n",
    "df['F_log'] = np.log1p(df['F'])\n",
    "df['M1_log'] = np.log1p(df['M1'])\n",
    "df['M2_log'] = np.log1p(df['M2'])\n",
    "\n",
    "# Features\n",
    "features = list(df.columns)\n",
    "features.remove('R')\n",
    "features.remove('F')\n",
    "features.remove('M1')\n",
    "features.remove('M2')\n",
    "\n",
    "# StandardScaler\n",
    "X_features = df[features].values\n",
    "\n",
    "# KMeans\n",
    "kmeans = KMeans(n_clusters=4, random_state=0)\n",
    "labels = kmeans.fit_predict(X_features)\n",
    "df[\"cluster_label\"] = labels\n",
    "\n",
    "# 실루엣 스코어\n",
    "silhouette_kmeans = silhouette_score(X_features, labels)\n",
    "print(f\"실루엣 스코어: {silhouette_kmeans:.3f}\")\n",
    "\n",
    "visualize_silhouette([3,4,5], X_features)\n",
    "visualize_kmeans_plot_multi([3,4,5], X_features)\n",
    "\n",
    "##4. 로그변환+표준화O\n",
    "\n",
    "# 로그 변환\n",
    "df['R_log'] = np.log1p(df['R'])\n",
    "df['F_log'] = np.log1p(df['F'])\n",
    "df['M1_log'] = np.log1p(df['M1'])\n",
    "df['M2_log'] = np.log1p(df['M2'])\n",
    "\n",
    "# Features\n",
    "features = list(df.columns)\n",
    "features.remove('R')\n",
    "features.remove('F')\n",
    "features.remove('M1')\n",
    "features.remove('M2')\n",
    "\n",
    "# StandardScaler\n",
    "X_features = df[features].values\n",
    "X_features_scaled = StandardScaler().fit_transform(X_features)\n",
    "\n",
    "# KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "labels = kmeans.fit_predict(X_features_scaled)\n",
    "df[\"cluster_label\"] = labels\n",
    "\n",
    "# 실루엣 스코어\n",
    "silhouette_kmeans = silhouette_score(X_features_scaled, labels)\n",
    "print(f\"실루엣 스코어: {silhouette_kmeans:.3f}\")\n",
    "\n",
    "visualize_silhouette([3,4,5], X_features_scaled)\n",
    "visualize_kmeans_plot_multi([3,4,5], X_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "777facee"
   },
   "outputs": [],
   "source": [
    "#최종 클러스터링 결과 분석\n",
    "print(df['cluster_label'].value_counts())\n",
    "display(df.groupby('cluster_label').mean())\n",
    "temp = df.groupby(['cluster_label']).mean()\n",
    "cluster_mean = temp.transpose()\n",
    "mean_table = cluster_mean.div(cluster_mean.max(axis=1), axis= 0)\n",
    "df.to_csv('final_cluster.csv', encoding='utf-8-sig')\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(mean_table, annot=True, fmt ='.2f', linewidths = 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b6d2bf6"
   },
   "source": [
    "# 고객별 상품 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "452b44e9"
   },
   "outputs": [],
   "source": [
    "##라이브러리 로드\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import random\n",
    "import implicit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "os.environ['OPENBLAS_NUM_THREADS']='1'\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "os.environ['MKL_NUM_THREADS']='1'\n",
    "%cd /Users/diekim/Desktop/ETC/LPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91d415a1"
   },
   "outputs": [],
   "source": [
    "##함수 정의\n",
    "def make_train (matrix, percentage = .2):\n",
    "    '''\n",
    "    -----------------------------------------------------\n",
    "    설명\n",
    "    유저-아이템 행렬 (matrix)에서 \n",
    "    1. 0 이상의 값을 가지면 1의 값을 갖도록 binary하게 테스트 데이터를 만들고\n",
    "    2. 훈련 데이터는 원본 행렬에서 percentage 비율만큼 0으로 바뀜\n",
    "    \n",
    "    -----------------------------------------------------\n",
    "    반환\n",
    "    training_set: 훈련 데이터에서 percentage 비율만큼 0으로 바뀐 행렬\n",
    "    test_set:     원본 유저-아이템 행렬의 복사본\n",
    "    user_inds:    훈련 데이터에서 0으로 바뀐 유저의 index\n",
    "    '''\n",
    "    test_set = matrix.copy()\n",
    "    test_set[test_set !=0] = 1 # binary하게 만들기\n",
    "    \n",
    "    training_set = matrix.copy()\n",
    "    nonzero_inds = training_set.nonzero()\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1]))\n",
    "    \n",
    "    random.seed(0)\n",
    "    num_samples = int(np.ceil(percentage * len(nonzero_pairs)))\n",
    "    samples = random.sample (nonzero_pairs, num_samples)\n",
    "    \n",
    "    user_inds = [index[0] for index in samples]\n",
    "    item_inds = [index[1] for index in samples]\n",
    "    \n",
    "    training_set[user_inds, item_inds] = 0\n",
    "    training_set.eliminate_zeros()\n",
    "    \n",
    "    return training_set, test_set, list(set(user_inds))\n",
    "\n",
    "def auc_score(test, predictions):\n",
    "    '''\n",
    "    fpr, tpr를 이용해서 AUC를 계산하는 함수\n",
    "    '''\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
    "    return metrics.auc(fpr,tpr)\n",
    "\n",
    "def calc_mean_auc(training_set, altered_users, predictions, test_set):\n",
    "    '''\n",
    "    가려진 정보가 있는 유저마다 AUC 평균을 구하는 함수\n",
    "    ----------------------------------------\n",
    "    input\n",
    "    1. training_set: make_train 함수에서 만들어진 훈련 데이터 (일정 비율로 아이템 구매량이 0으로 가려진 데이터)\n",
    "    2. prediction: implicit MF에서 나온 유저/아이템 별로 나온 예측 평점 행렬\n",
    "    3. altered_users: make_train 함수에서 아이템 구매량이 0으로 가려진 유저\n",
    "    4. test_set: make_train함수에서 만든 테스트 데이터\n",
    "    ----------------------------------------\n",
    "    반환\n",
    "    추천 시스템 유저의 평균 auc\n",
    "    인기아이템 기반 유저 평균 auc\n",
    "    '''\n",
    "    # 리스트 초기화\n",
    "    store_auc = []\n",
    "    popularity_auc = []\n",
    "    \n",
    "    pop_items = np.array(test_set.sum(axis = 0)).reshape(-1) # 모든 유저의 아이템별 구매횟수 합\n",
    "    item_vecs = predictions[1] # 아이템 latent 벡터\n",
    "    \n",
    "    for user in altered_users:\n",
    "        training_row = training_set[user,:].toarray().reshape(-1) # 유저의 훈련데이터\n",
    "        zero_inds = np.where(training_row == 0) # 가려진 아이템 Index\n",
    "        \n",
    "        # 가려진 아이템에 대한 예측\n",
    "        user_vec = predictions[0][user,:]\n",
    "        pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "        \n",
    "        # 가려진 아이템에 대한 실제값\n",
    "        actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1) \n",
    "        \n",
    "        # 가려진 아이템에 대한 popularity (구매횟수 합)\n",
    "        pop = pop_items[zero_inds]\n",
    "        \n",
    "        # AUC 계산 \n",
    "        store_auc.append(auc_score(actual, pred))\n",
    "        popularity_auc.append(auc_score(actual,pop))\n",
    "    \n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
    "\n",
    "# def get_items_purchased(customer_id, mf_train, customer_list, products_list, item_lookup):\n",
    "#     '''\n",
    "#     특정 유저가 구매한 목록을 보여주는 함수\n",
    "#     ----------------------------------------\n",
    "#     INPUT\n",
    "#     1. customer_id: 고객 ID\n",
    "#     2. mf_train: 훈련 데이터 평점\n",
    "#     3. customers_list: 훈련 데이터에 쓰인 고객 목록\n",
    "#     4. products_list: 훈련 데이터에 쓰인 아이템 목록\n",
    "#     5. item_lookup: 유니크한 아이템 ID와 설명을 담은 테이블\n",
    "#     '''\n",
    "#     cust_ind = np.where (customer_list == customer_id)[0][0]\n",
    "#     purchased_ind = mf_train[cust_ind,:].nonzero()[1]\n",
    "#     prod_codes = products_list[purchased_ind]\n",
    "    \n",
    "#     return item_lookup.loc[item_lookup.StockCode.isin(prod_codes)]\n",
    "\n",
    "# def rec_items(customer_id, mf_train, user_vecs, item_vecs, customer_list, item_list, item_lookup, num_items = 10):\n",
    "#     '''\n",
    "#     유저의 추천 아이템 반환\n",
    "#     -----------------------------------------------------\n",
    "#     INPUT\n",
    "#     1. customer_id - Input the customer's id number that you want to get recommendations for\n",
    "#     2. mf_train: 훈련 데이터\n",
    "#     3. user_vecs: 행렬 분해에 쓰인 유저 벡터\n",
    "#     4. item_vecs: 행렬 분해에 쓰인 아이템 벡터\n",
    "#     5. customer_list: 평점 행렬의 행에 해당하는 고객 ID\n",
    "#     6. item_list: 평점 행렬의 열에 해당하는 아이템 ID\n",
    "#     7. item_lookup: 아이템 ID와 설명을 담은 테이블\n",
    "#     8. num_items: 추천할 아이템 개수\n",
    "#     -----------------------------------------------------\n",
    "#     반환    \n",
    "#     구매한 적이 없는 아이템 중 예측 평점이 높은 최고 n개의 추천 아이템\n",
    "#     '''\n",
    "    \n",
    "#     cust_ind = np.where(customer_list == customer_id)[0][0]\n",
    "#     pref_vec = mf_train[cust_ind,:].toarray()                   # 훈련 데이터의 실제 평점\n",
    "#     pref_vec = pref_vec.reshape(-1) + 1                         # 1을 더해서 환불한 것도 구매한 걸로 간주\n",
    "#     pref_vec[pref_vec > 1] = 0                                  # 구매한 것들을 모두 0으로 \n",
    "#     rec_vector = user_vecs[cust_ind,:].dot(item_vecs.T)         # 추천 시스템에 기반한 예측 평점\n",
    "    \n",
    "#     # Min-Max Scaling\n",
    "#     min_max = MinMaxScaler()\n",
    "#     rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1,1))[:,0] \n",
    "#     recommend_vector = pref_vec*rec_vector_scaled  # 구매하지 않은 아이템에 대해서만 예측 평점이 남도록\n",
    "    \n",
    "#     product_idx = np.argsort(recommend_vector)[::-1][:num_items] # num_items만큼 내림차순으로 평점 정렬한 index\n",
    "    \n",
    "#     rec_list = []\n",
    "    \n",
    "#     for index in product_idx:\n",
    "#         code = item_list[index] # 아이템 id\n",
    "#         # id와 description 담기\n",
    "#         rec_list.append([code, item_lookup['Description'].loc[item_lookup['pd_c'] == code].iloc[0]]) \n",
    "    \n",
    "#     codes = [item[0] for item in rec_list]\n",
    "#     descriptions = [item[1] for item in rec_list]\n",
    "#     final_frame = pd.DataFrame({'pd_c': codes, 'Description': descriptions})\n",
    "    \n",
    "#     return final_frame[['pd_c', 'Description']]\n",
    "\n",
    "def recommendation(usernum, cluster, n=10):\n",
    "    userid = grouped[grouped['고객번호']==usernum]['userid'].values[0]\n",
    "    recommendations = model.recommend(userid, csr_mat[userid], N=n)\n",
    "    item_df = df[['상품코드', '대분류명', '중분류명', '소분류명']]\n",
    "    res_df = pd.DataFrame()\n",
    "    for i in range(n):\n",
    "        print('userid: {}의 TOP{} 아이템 추천 테이블 생성 중...'.format(userid, i+1))\n",
    "        rec_df = grouped[grouped['itemid']==recommendations[0][i]]['상품코드'].drop_duplicates()\n",
    "        tmp_df = pd.merge(rec_df, item_df, on='상품코드', how='left').drop_duplicates()\n",
    "        tmp_df['구매확률'] = recommendations[1][i]\n",
    "        res_df = pd.concat([res_df, tmp_df], axis=0)\n",
    "        res_df['고객번호'] = usernum\n",
    "        res_df['클러스터'] = cluster\n",
    "        res_df = res_df.reset_index(drop=True)\n",
    "        #res_df.to_csv('{}_top10.csv'.format(userid), encoding='utf-8-sig')\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3e77bf56"
   },
   "outputs": [],
   "source": [
    "##데이터 정리\n",
    "df = pd.read_csv('products.csv')\n",
    "\n",
    "df.rename(columns={'대분류명': '중분류명',\n",
    "                   '중분류명': '대분류명'},\n",
    "          inplace=True)\n",
    "\n",
    "grouped = df.groupby(['고객번호', '상품코드'])['구매수량'].sum().reset_index()\n",
    "\n",
    "customers = list(np.sort(grouped['고객번호'].unique()))\n",
    "products = list (grouped['상품코드'].unique())\n",
    "quantity = list(grouped['구매수량'])\n",
    "\n",
    "rows = grouped['고객번호'].astype('category').cat.codes\n",
    "cols = grouped['상품코드'].astype('category').cat.codes\n",
    "\n",
    "grouped['userid'] = rows\n",
    "grouped['itemid'] = cols\n",
    "\n",
    "print(len(customers)) \n",
    "print(len(products))  \n",
    "\n",
    "csr_mat = sparse.csr_matrix((quantity, (rows, cols)), shape = (len(customers),len(products)))\n",
    "matrix_size = csr_mat.shape[0]* csr_mat.shape[1]\n",
    "num_purchases = len(csr_mat.nonzero()[0])\n",
    "sparsity = 100 * (1 - (num_purchases / matrix_size))\n",
    "print(sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ed3d7c7c"
   },
   "outputs": [],
   "source": [
    "##모델 적합\n",
    "product_train, product_test, product_users_altered = make_train(csr_mat, 0.2)\n",
    "model = implicit.als.AlternatingLeastSquares(factors=20,\n",
    "                                             regularization=0.1,\n",
    "                                             iterations=30)\n",
    "alpha = 15\n",
    "model.fit((product_train*alpha).astype('double'))\n",
    "\n",
    "user_vecs = model.user_factors\n",
    "item_vecs = model.item_factors\n",
    "predictions = [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)]\n",
    "print(calc_mean_auc(product_train, product_users_altered, predictions, product_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "307c2c11"
   },
   "outputs": [],
   "source": [
    "##최종 추천\n",
    "df1 = recommendation(usernum='M124357021', cluster=0, n=10) \n",
    "df2 = recommendation(usernum='M282063613', cluster=0, n=10) \n",
    "df3 = recommendation(usernum='M576689847', cluster=0, n=10) \n",
    "df4 = recommendation(usernum='M057015266', cluster=1, n=10) \n",
    "df5 = recommendation(usernum='M596502154', cluster=1, n=10) \n",
    "df6 = recommendation(usernum='M378415176', cluster=1, n=10) \n",
    "df7 = recommendation(usernum='M408936009', cluster=2, n=10) \n",
    "df8 = recommendation(usernum='M652598612', cluster=2, n=10) \n",
    "df9 = recommendation(usernum='M865603201', cluster=2, n=10) \n",
    "df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9], axis=0)\n",
    "df.to_csv('final_recsys.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8774dx5XBl5"
   },
   "source": [
    "# 고객별 재구매 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMjQMvTZXG2G"
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBB4oAi4XKo1"
   },
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d502d964"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from pandas import DataFrame , concat\n",
    "from sklearn.metrics import mean_absolute_error , mean_squared_error\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from numpy import mean , concatenate\n",
    "from math import sqrt\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM,Activation\n",
    "from numpy import array , hstack\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGrPbrEbKBU9"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/gdrive/MyDrive/Project/lotte/data/products_cltv.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "742480c4"
   },
   "outputs": [],
   "source": [
    "df['고객번호'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0b79514d"
   },
   "outputs": [],
   "source": [
    "df[df['고객번호']=='M057015266']['대분류명'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lhmUmgnBQug"
   },
   "outputs": [],
   "source": [
    "id= 'M057015266'\n",
    "product = '과자'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWDHPCQbYPY1"
   },
   "source": [
    "### 날짜만"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRz9Mvq9Yl6K"
   },
   "source": [
    "#### 데이터프레임 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0g-N4xuKKBpD"
   },
   "outputs": [],
   "source": [
    "data = df[(df['고객번호']==id) & (df['대분류명']==product)]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYOH7uAuKBpE"
   },
   "outputs": [],
   "source": [
    "data['구매일자'] = data['구매일자'].astype('str')\n",
    "data['구매일자'] = pd.to_datetime(data['구매일자'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "602481e6"
   },
   "outputs": [],
   "source": [
    "# lpay 사용, 미사용 데이터프레임 나눠서 사용금액 나누기\n",
    "lpay = data[data['Lpay']==1]\n",
    "lpay_X = data[data['Lpay']==0]\n",
    "\n",
    "lpay['lpay_구매금액'] = lpay['구매금액']\n",
    "lpay['lpay_구매금액X'] = 0\n",
    "lpay_X['lpay_구매금액'] = 0\n",
    "lpay_X['lpay_구매금액X'] = lpay_X['구매금액']\n",
    "\n",
    "data = pd.concat([lpay, lpay_X], axis = 0)\n",
    "data = data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLGdFrhKKBpF"
   },
   "outputs": [],
   "source": [
    "data = data.groupby('구매일자').agg({'고객번호':'count',\n",
    "                         '채널구분(1:오프, 2:온)':'mean',\n",
    "                         'Lpay':'sum',\n",
    "                         'lpay_구매금액':'sum',\n",
    "                         '구매시간':'mean',\n",
    "                         '구매수량':'sum',\n",
    "                         '구매금액':'sum'})\n",
    "data.columns = ['거래건수','온/오프_평균','Lpay거래건수','Lpay구매금액_총합','구매시간_평균','구매수량','구매금액_총합']\n",
    "data = data[['거래건수','온/오프_평균','Lpay거래건수','Lpay구매금액_총합','구매시간_평균','구매금액_총합','구매수량']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15670fa8"
   },
   "outputs": [],
   "source": [
    "# 중간 날짜 데이터 채우기\n",
    "data_index_list = data.index.tolist()\n",
    "for i in range(len(data_index_list)-1) : \n",
    "    start_date = pd.to_datetime(str(data_index_list[i])[:10]) ## 시작 날짜\n",
    "    end_date = pd.to_datetime(str(data_index_list[i+1])[:10]) ## 마지막 날짜\n",
    "    dates = pd.date_range(start_date,end_date,freq='D') ## 일단위로 생성\n",
    "    \n",
    "    tt = pd.DataFrame(index = dates, columns = data.columns)\n",
    "    tt = tt.fillna(0)\n",
    "    tt = tt[1:-1]\n",
    "    data = pd.concat([data, tt], axis = 0)\n",
    "    data = data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5477502b"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6c2f16a6"
   },
   "outputs": [],
   "source": [
    "DATE = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "623a5f14"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da86a44b"
   },
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ec7509c6"
   },
   "outputs": [],
   "source": [
    "x_1 = data['거래건수'].values\n",
    "x_2 = data['온/오프_평균'].values\n",
    "x_3 = data['Lpay거래건수'].values\n",
    "x_4 = data['Lpay구매금액_총합'].values\n",
    "x_5 = data['구매시간_평균'].values\n",
    "x_6 = data['구매금액_총합'].values\n",
    "y = data['구매수량'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "572a2f36"
   },
   "outputs": [],
   "source": [
    "# Step 1 : convert to [rows, columns] structure\n",
    "x_1 = x_1.reshape((len(x_1), 1))\n",
    "x_2 = x_2.reshape((len(x_2), 1))\n",
    "x_3 = x_3.reshape((len(x_3), 1))\n",
    "x_4 = x_3.reshape((len(x_4), 1))\n",
    "x_5 = x_3.reshape((len(x_5), 1))\n",
    "x_6 = x_3.reshape((len(x_6), 1))\n",
    "\n",
    "y = y.reshape((len(y), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0e986b7"
   },
   "outputs": [],
   "source": [
    "print (\"x_1.shape\" , x_1.shape) \n",
    "print (\"x_2.shape\" , x_2.shape) \n",
    "print (\"x_3.shape\" , x_3.shape) \n",
    "print (\"y.shape\" , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3NkyVRnpk6L"
   },
   "outputs": [],
   "source": [
    "pip install varname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swiGGRfQcUIW"
   },
   "outputs": [],
   "source": [
    "def MinMaxScaler(x) : \n",
    "  x_MinMax = (x - x.min(axis=0)) / (x.max(axis=0) - x.min(axis=0))\n",
    "  return x_MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1HvNPUZGrJyT"
   },
   "outputs": [],
   "source": [
    "min_dict = {}\n",
    "max_dict = {}\n",
    "min_dict['x_1'] = x_1.min(axis = 0)[0]\n",
    "max_dict['x_1'] = x_1.max(axis = 0)[0]\n",
    "min_dict['x_2'] = x_2.min(axis = 0)[0]\n",
    "max_dict['x_2'] = x_2.max(axis = 0)[0]\n",
    "min_dict['x_3'] = x_3.min(axis = 0)[0]\n",
    "max_dict['x_3'] = x_3.max(axis = 0)[0]\n",
    "min_dict['x_4'] = x_4.min(axis = 0)[0]\n",
    "max_dict['x_4'] = x_4.max(axis = 0)[0]\n",
    "min_dict['x_5'] = x_5.min(axis = 0)[0]\n",
    "max_dict['x_5'] = x_5.max(axis = 0)[0]\n",
    "min_dict['x_6'] = x_6.min(axis = 0)[0]\n",
    "max_dict['x_6'] = x_6.max(axis = 0)[0]\n",
    "min_dict['y'] = y.min(axis = 0)[0]\n",
    "max_dict['y'] = y.max(axis = 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3mtoG5-drhhx"
   },
   "outputs": [],
   "source": [
    "min_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38669df9"
   },
   "outputs": [],
   "source": [
    "# Step 2 : normalization \n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_1_scaled = MinMaxScaler_(x_1)\n",
    "x_2_scaled = MinMaxScaler_(x_2)\n",
    "x_3_scaled = MinMaxScaler_(x_3)\n",
    "x_4_scaled = MinMaxScaler_(x_4)\n",
    "x_5_scaled = MinMaxScaler_(x_5)\n",
    "x_6_scaled = MinMaxScaler_(x_6)\n",
    "\n",
    "y_scaled = MinMaxScaler_(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6f1daa13"
   },
   "outputs": [],
   "source": [
    "# Step 3 : horizontally stack columns\n",
    "dataset_stacked = hstack((x_1_scaled, x_2_scaled, x_3_scaled, x_4_scaled, x_5_scaled, x_6_scaled, y_scaled))\n",
    "print (\"dataset_stacked.shape\" , dataset_stacked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "814ebd43"
   },
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    " X, y = list(), list()\n",
    " for i in range(len(sequences)):\n",
    "  # find the end of this pattern\n",
    "  end_ix = i + n_steps_in\n",
    "  out_end_ix = end_ix + n_steps_out-1\n",
    "  # check if we are beyond the dataset\n",
    "  if out_end_ix > len(sequences):\n",
    "   break\n",
    "  # gather input and output parts of the pattern\n",
    "  seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "  X.append(seq_x)\n",
    "  y.append(seq_y)\n",
    " return array(X), array(y)\n",
    "# choose a number of time steps #change this accordingly\n",
    "n_steps_in, n_steps_out = 1 , 1\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset_stacked, n_steps_in, n_steps_out)\n",
    "print (\"X.shape\" , X.shape) \n",
    "print (\"y.shape\" , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0e9594fb"
   },
   "outputs": [],
   "source": [
    "split_point = int(len(data) * 0.9)\n",
    "train_X , train_y = X[:split_point, :] , y[:split_point, :]\n",
    "test_X , test_y = X[split_point:, :] , y[split_point:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6693e927"
   },
   "outputs": [],
   "source": [
    "#optimizer learning rate\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps_in, 6)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(loss='mse' , optimizer=opt , metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50e93b42"
   },
   "outputs": [],
   "source": [
    "# Fit network\n",
    "history = model.fit(train_X , train_y , epochs=100 , steps_per_epoch=25 , verbose=1 ,validation_data=(test_X, test_y) ,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2ACcSF4afop"
   },
   "outputs": [],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGKu-wFkapYj"
   },
   "outputs": [],
   "source": [
    "model.evaluate(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0c2d305"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "675d7fa9"
   },
   "outputs": [],
   "source": [
    "xx = pd.DataFrame(train_y, index = data.index[:split_point])\n",
    "yy = pd.DataFrame(test_y, index = data.index[split_point:])\n",
    "true = pd.concat([xx, yy], axis = 0)\n",
    "pred = pd.DataFrame(pred, index = data.index[split_point:])\n",
    "pred[0] = pred[0].apply(lambda x : x if x>=0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62c2591c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.plot(true, label = 'TRUE VALUE')\n",
    "plt.plot(pred, label = 'PREDICT VALUE')\n",
    "plt.xlim(datetime.datetime(2021,11,1),datetime.datetime(2022,1,15))\n",
    "plt.ylim(0,0.6)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJj5sJhneFh4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9c9297e3"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(yy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e43deaf9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "mean_squared_error(yy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0a47083"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "MSE = mean_squared_error(yy, pred) \n",
    "np.sqrt(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f36ae6b4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "mean_squared_log_error(yy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e39b7552"
   },
   "outputs": [],
   "source": [
    "def MAPE(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100 \n",
    "    \n",
    "MAPE(yy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0025eda"
   },
   "outputs": [],
   "source": [
    "def MAE(y_test, y_pred): \n",
    "    return np.mean((y_test - y_pred) / y_test) * 100\n",
    "    \n",
    "MAE(yy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-L6LeMHle9ML"
   },
   "outputs": [],
   "source": [
    "def MinMax_to_Raw(x_MinMax, min_value, max_value) : \n",
    "  x = map(int, x_MinMax * (max_value - min_value) +  min_value)\n",
    "  return list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaYVwjYqe9MM"
   },
   "outputs": [],
   "source": [
    "y_raw = pd.DataFrame(MinMax_to_Raw(y_scaled, min_dict['y'], max_dict['y']), index = data.index)\n",
    "y_pred = pd.DataFrame(MinMax_to_Raw(pred, min_dict['y'], max_dict['y']), index = data.index[split_point:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWoR3RPWsm-e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.plot(y_raw, label = 'real value')\n",
    "plt.plot(y_pred, label = 'predicted')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsZU3yX8vHyd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yqv1CoKDvH0V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkPgnouHYSZ0"
   },
   "source": [
    "### 날짜 + 시간"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cHVsmY1yMJI"
   },
   "source": [
    "#### 데이터프레임 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nALemLD_yncB"
   },
   "outputs": [],
   "source": [
    "data = df[(df['고객번호']==id) & (df['대분류명']==product)]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0Uwab7_y0OC"
   },
   "outputs": [],
   "source": [
    "# 시간 변환 함수1: 1 -> 01:00:00 \n",
    "def convert_time1(x):\n",
    "    if x<10:\n",
    "      return '0'+str(x)+':00:00'\n",
    "    else:\n",
    "      return str(x)+':00:00'\n",
    "\n",
    "# 시간 변환\n",
    "data['구매시간'] = data['구매시간'].apply(lambda x:convert_time1(x))\n",
    "data = data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mAI7RcBy3op"
   },
   "outputs": [],
   "source": [
    "# time 변수 생성\n",
    "\n",
    "for i in range(len(data)):\n",
    "  data['구매일자'][i] = str(data['구매일자'][i]) + ' ' + data['구매시간'][i]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LipZVBXWyncC"
   },
   "outputs": [],
   "source": [
    "data['구매일자'] = data['구매일자'].astype('str')\n",
    "data['구매일자'] = pd.to_datetime(data['구매일자'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "baVy4MExyncD"
   },
   "outputs": [],
   "source": [
    "# lpay 사용, 미사용 데이터프레임 나눠서 사용금액 나누기\n",
    "lpay = data[data['Lpay']==1]\n",
    "lpay_X = data[data['Lpay']==0]\n",
    "\n",
    "lpay['lpay_구매금액'] = lpay['구매금액']\n",
    "lpay['lpay_구매금액X'] = 0\n",
    "lpay_X['lpay_구매금액'] = 0\n",
    "lpay_X['lpay_구매금액X'] = lpay_X['구매금액']\n",
    "\n",
    "data = pd.concat([lpay, lpay_X], axis = 0)\n",
    "data = data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sE7iQIocyncD"
   },
   "outputs": [],
   "source": [
    "data = data.groupby('구매일자').agg({'고객번호':'count',\n",
    "                         '채널구분(1:오프, 2:온)':'mean',\n",
    "                         'Lpay':'sum',\n",
    "                         'lpay_구매금액':'sum',\n",
    "                         '구매수량':'sum',\n",
    "                         '구매금액':'sum'})\n",
    "data.columns = ['거래건수','온/오프_평균','Lpay거래건수','Lpay구매금액_총합','구매수량','구매금액_총합']\n",
    "data = data[['거래건수','온/오프_평균','Lpay거래건수','Lpay구매금액_총합','구매금액_총합','구매수량']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvNf8KTWyMJJ"
   },
   "outputs": [],
   "source": [
    "# 중간 날짜 데이터 채우기\n",
    "data_index_list = data.index.tolist()\n",
    "for i in range(len(data_index_list)-1) : \n",
    "  start_date = data.index[i] ## 시작 날짜\n",
    "  end_date = data.index[i+1] ## 마지막 날짜\n",
    "  dates = pd.date_range(start_date,end_date,freq='H') ## 시간 단위로 생성\n",
    "  \n",
    "  tt = pd.DataFrame(index = dates, columns = data.columns)\n",
    "  tt = tt.fillna(0)\n",
    "  tt = tt[1:-1]\n",
    "  data = pd.concat([data, tt], axis = 0)\n",
    "data = data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KOXYAGSyMJJ"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9XkmBiufKjdc"
   },
   "outputs": [],
   "source": [
    "data[['구매수량']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MR_1bK1DyMJK"
   },
   "outputs": [],
   "source": [
    "DATE = data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MHhORvXyMJK"
   },
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8t2JodGWyMJL"
   },
   "outputs": [],
   "source": [
    "x_1 = data['거래건수'].values\n",
    "x_2 = data['온/오프_평균'].values\n",
    "x_3 = data['Lpay거래건수'].values\n",
    "x_4 = data['Lpay구매금액_총합'].values\n",
    "x_5 = data['구매금액_총합'].values\n",
    "y = data['구매수량'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymNq02pRyMJL"
   },
   "outputs": [],
   "source": [
    "# Step 1 : convert to [rows, columns] structure\n",
    "x_1 = x_1.reshape((len(x_1), 1))\n",
    "x_2 = x_2.reshape((len(x_2), 1))\n",
    "x_3 = x_3.reshape((len(x_3), 1))\n",
    "x_4 = x_3.reshape((len(x_4), 1))\n",
    "x_5 = x_3.reshape((len(x_5), 1))\n",
    "\n",
    "y = y.reshape((len(y), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xmLA11OyMJL"
   },
   "outputs": [],
   "source": [
    "print (\"x_1.shape\" , x_1.shape) \n",
    "print (\"x_2.shape\" , x_2.shape) \n",
    "print (\"x_3.shape\" , x_3.shape) \n",
    "print (\"y.shape\" , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSG5FL1PyMJL"
   },
   "outputs": [],
   "source": [
    "# pip install varname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yz0NO5F4yMJM"
   },
   "outputs": [],
   "source": [
    "def MinMaxScaler(x) : \n",
    "  x_MinMax = (x - x.min(axis=0)) / (x.max(axis=0) - x.min(axis=0))\n",
    "  return x_MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kAj3GMIKyMJM"
   },
   "outputs": [],
   "source": [
    "min_dict = {}\n",
    "max_dict = {}\n",
    "min_dict['x_1'] = x_1.min(axis = 0)[0]\n",
    "max_dict['x_1'] = x_1.max(axis = 0)[0]\n",
    "min_dict['x_2'] = x_2.min(axis = 0)[0]\n",
    "max_dict['x_2'] = x_2.max(axis = 0)[0]\n",
    "min_dict['x_3'] = x_3.min(axis = 0)[0]\n",
    "max_dict['x_3'] = x_3.max(axis = 0)[0]\n",
    "min_dict['x_4'] = x_4.min(axis = 0)[0]\n",
    "max_dict['x_4'] = x_4.max(axis = 0)[0]\n",
    "min_dict['x_5'] = x_5.min(axis = 0)[0]\n",
    "max_dict['x_5'] = x_5.max(axis = 0)[0]\n",
    "min_dict['y'] = y.min(axis = 0)[0]\n",
    "max_dict['y'] = y.max(axis = 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2rm6zXEyMJM"
   },
   "outputs": [],
   "source": [
    "max_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pf3x66sDyMJM"
   },
   "outputs": [],
   "source": [
    "# Step 2 : normalization \n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_1_scaled = MinMaxScaler_(x_1)\n",
    "x_2_scaled = MinMaxScaler_(x_2)\n",
    "x_3_scaled = MinMaxScaler_(x_3)\n",
    "x_4_scaled = MinMaxScaler_(x_4)\n",
    "x_5_scaled = MinMaxScaler_(x_5)\n",
    "\n",
    "y_scaled = MinMaxScaler_(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3YoO40RPyMJM"
   },
   "outputs": [],
   "source": [
    "# Step 3 : horizontally stack columns\n",
    "dataset_stacked = hstack((x_1_scaled, x_2_scaled, x_3_scaled, x_4_scaled, x_5_scaled, y_scaled))\n",
    "print (\"dataset_stacked.shape\" , dataset_stacked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvLWPyf9yMJN"
   },
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    " X, y = list(), list()\n",
    " for i in range(len(sequences)):\n",
    "  # find the end of this pattern\n",
    "  end_ix = i + n_steps_in\n",
    "  out_end_ix = end_ix + n_steps_out-1\n",
    "  # check if we are beyond the dataset\n",
    "  if out_end_ix > len(sequences):\n",
    "   break\n",
    "  # gather input and output parts of the pattern\n",
    "  seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "  X.append(seq_x)\n",
    "  y.append(seq_y)\n",
    " return array(X), array(y)\n",
    "# choose a number of time steps #change this accordingly\n",
    "n_steps_in, n_steps_out = 1 , 1\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset_stacked, n_steps_in, n_steps_out)\n",
    "print (\"X.shape\" , X.shape) \n",
    "print (\"y.shape\" , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NObrOg39yMJN"
   },
   "outputs": [],
   "source": [
    "split_point = int(len(data) * 0.9)\n",
    "train_X , train_y = X[:split_point, :] , y[:split_point, :]\n",
    "test_X , test_y = X[split_point:, :] , y[split_point:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9zMopgayMJN"
   },
   "outputs": [],
   "source": [
    "#optimizer learning rate\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps_in, 5)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(loss='mse' , optimizer=opt , metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vydt4AsVyMJO"
   },
   "outputs": [],
   "source": [
    "# Fit network\n",
    "history = model.fit(train_X , train_y , epochs=100 , steps_per_epoch=25 , verbose=1 ,validation_data=(test_X, test_y) ,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oyVAw6fnyMJP"
   },
   "outputs": [],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIMyi6GxyMJQ"
   },
   "outputs": [],
   "source": [
    "model.evaluate(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTujp4HnyMJR"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmuZqnky2pX2"
   },
   "outputs": [],
   "source": [
    "len(data.index[split_point:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0GtEAAuP3FPc"
   },
   "outputs": [],
   "source": [
    "split_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRLOZTJe3IJO"
   },
   "outputs": [],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yriXDND24Lp"
   },
   "outputs": [],
   "source": [
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymD4QcXCyMJR"
   },
   "outputs": [],
   "source": [
    "xx = pd.DataFrame(train_y, index = data.index[:split_point])\n",
    "yy = pd.DataFrame(test_y, index = data.index[split_point:])\n",
    "true = pd.concat([xx, yy], axis = 0)\n",
    "pred = pd.DataFrame(pred, index = data.index[split_point:])\n",
    "pred[0] = pred[0].apply(lambda x : x if x>=0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inh1qEc4yMJS"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.plot(true, label = 'TRUE VALUE')\n",
    "plt.plot(pred, label = 'PREDICT VALUE')\n",
    "plt.xlim(datetime.datetime(2021,11,1),datetime.datetime(2022,1,1))\n",
    "plt.ylim(0,0.6)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-LQe2btCyMJS"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(yy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgHZ-s3tyMJT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "mean_squared_error(yy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9Bb2GKnyMJT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "MSE = mean_squared_error(yy, pred) \n",
    "np.sqrt(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NX6bTIQyMJT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "mean_squared_log_error(yy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYeL6HKbyMJT"
   },
   "outputs": [],
   "source": [
    "def MAPE(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100 \n",
    "    \n",
    "MAPE(yy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmPPZ_WFyMJT"
   },
   "outputs": [],
   "source": [
    "def MAE(y_test, y_pred): \n",
    "    return np.mean((y_test - y_pred) / y_test) * 100\n",
    "    \n",
    "MAE(yy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTLaQ4xUyMJU"
   },
   "outputs": [],
   "source": [
    "def MinMax_to_Raw(x_MinMax, min_value, max_value) : \n",
    "  x = map(int, x_MinMax * (max_value - min_value) +  min_value)\n",
    "  return list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pglcsgu1yMJU"
   },
   "outputs": [],
   "source": [
    "y_raw = pd.DataFrame(MinMax_to_Raw(y_scaled, min_dict['y'], max_dict['y']), index = data.index)\n",
    "y_pred = pd.DataFrame(MinMax_to_Raw(np.array(pred), min_dict['y'], max_dict['y']), index = data.index[split_point:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zoXibhTkyMJU"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.plot(y_raw, label = 'real value')\n",
    "plt.plot(y_pred, label = 'predicted')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32Vv79nyXrN7"
   },
   "source": [
    "## Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q3xl17fLQZES"
   },
   "outputs": [],
   "source": [
    "!pip install pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ul1DQ5EcQ7Nx"
   },
   "outputs": [],
   "source": [
    "pip install --upgrade plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ouUMPvpyKi-7"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yb4w4n0JKw1K"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "mpl.rc('font', family='Malgun Gothic') # 폰트 설정\n",
    "mpl.rc('axes', unicode_minus=False) # 유니코드에서 음수 부호 설정\n",
    "\n",
    "# 차트 스타일 설정\n",
    "sns.set(font=\"Malgun Gothic\", rc={\"axes.unicode_minus\":False}, style='darkgrid')\n",
    "plt.rc(\"figure\", figsize=(10,8))\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkCisOpzdINQ"
   },
   "source": [
    "### 1. 구매일자만 (구매시간 X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkAUBPDjK0rw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "product = pd.read_csv('/content/gdrive/MyDrive/Project/lotte/data/products.csv')\n",
    "product.set_index('고객번호',inplace=True)\n",
    "product.rename(columns={'대분류명':'중분류명','중분류명':'대분류명'},inplace=True)\n",
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGduOPneK034"
   },
   "outputs": [],
   "source": [
    "# 작성날짜 datetime으로 변환\n",
    "product['구매일자'] = product['구매일자'].astype('str')\n",
    "product['구매일자'] = pd.to_datetime(product['구매일자'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4_x43qpTcyT"
   },
   "outputs": [],
   "source": [
    "product.loc['M057015266']['대분류명'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMRHVpshLG_o"
   },
   "outputs": [],
   "source": [
    "customer1 = product.loc['M057015266'][product.loc['M057015266']['대분류명']=='과자'] ## 소분류명 구매수량 예측이 의미있을까,,? 너무 적은 데이터인데... -> 대분류명으로 해보기!\n",
    "customer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VSWHqHUMLHCP"
   },
   "outputs": [],
   "source": [
    "customer1_time = pd.DataFrame(customer1.groupby('구매일자')['구매수량'].sum().reset_index())\n",
    "customer1_time.rename(columns={'구매일자':'ds','구매수량':'y'}, inplace=True)\n",
    "customer1_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LgnSGH5FXT3Z"
   },
   "outputs": [],
   "source": [
    "customer1_time.set_index('ds').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu6sYooMLHE3"
   },
   "outputs": [],
   "source": [
    "m = Prophet()\n",
    "m.fit(customer1_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chL-buUZLHHf"
   },
   "outputs": [],
   "source": [
    "# make_future_dataframe() 함수를 이용해 예측값을 넣을 데이터 프레임을 생성\n",
    "# periods 값은 향후 몇일 (또는 주,월 등 단위 주기) 을 예측할 것인지를 의미 -> periods = 30 : 30일의 실적을 예측\n",
    "future = m.make_future_dataframe(periods=30)\n",
    "forecast = m.predict(future)\n",
    "fig1 = m.plot(forecast) # 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38kjug5jVfHZ"
   },
   "outputs": [],
   "source": [
    "# 피팅된 모델의 컴포넌트들을 시각화\n",
    "\n",
    "fig2 = m.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOyexMgMWSpl"
   },
   "outputs": [],
   "source": [
    "from prophet.plot import add_changepoints_to_plot\n",
    "\n",
    "m = Prophet(changepoint_prior_scale=0.05)\n",
    "m.fit(customer1_time)\n",
    "\n",
    "fig = m.plot(forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), m, forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNyBe5ljYf2E"
   },
   "outputs": [],
   "source": [
    "m = Prophet(changepoint_prior_scale=0.3)\n",
    "m.fit(customer1_time)\n",
    "\n",
    "fig = m.plot(forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), m, forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQvesxc-dNP5"
   },
   "source": [
    "### 2. 구매일자 + 구매시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEUPYPMtdNP5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "product = pd.read_csv('/content/drive/MyDrive/Project/lotte/data/products.csv')\n",
    "product.set_index('고객번호',inplace=True)\n",
    "product.rename(columns={'대분류명':'중분류명','중분류명':'대분류명'},inplace=True)\n",
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lz_fPbcNdNP6"
   },
   "outputs": [],
   "source": [
    "# 작성날짜 datetime으로 변환\n",
    "product['구매일자'] = product['구매일자'].astype('str')\n",
    "product['구매일자'] = pd.to_datetime(product['구매일자'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p79V1t_SdNP6"
   },
   "outputs": [],
   "source": [
    "product.loc['M057015266']['대분류명'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6BmYQKyfdNP6"
   },
   "outputs": [],
   "source": [
    "customer1 = product.loc['M057015266'][product.loc['M057015266']['대분류명']=='과자'] ## 소분류명 구매수량 예측이 의미있을까,,? 너무 적은 데이터인데... -> 대분류명으로 해보기!\n",
    "customer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3oQHm2RdNP7"
   },
   "outputs": [],
   "source": [
    "# 시간 변환 함수1: 1 -> 01:00:00 \n",
    "def convert_time1(x):\n",
    "    if x<10:\n",
    "      return '0'+str(x)+':00:00'\n",
    "    else:\n",
    "      return str(x)+':00:00'\n",
    "\n",
    "# 시간 변환\n",
    "customer1['구매시간'] = customer1['구매시간'].apply(lambda x:convert_time1(x))\n",
    "customer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_r6v6pXWdNP7"
   },
   "outputs": [],
   "source": [
    "# time 변수 생성\n",
    "\n",
    "for i in range(len(customer1)):\n",
    "  customer1['구매일자'][i] = str(customer1['구매일자'][i]) + ' ' + customer1['구매시간'][i]\n",
    "customer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRwN3wueeb3Z"
   },
   "outputs": [],
   "source": [
    "customer1['구매일자'] = pd.to_datetime(customer1['구매일자'])\n",
    "customer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7cQfg-JdNP8"
   },
   "outputs": [],
   "source": [
    "customer1_time = pd.DataFrame(customer1.groupby('구매일자')['구매수량'].sum().reset_index())\n",
    "customer1_time.rename(columns={'구매일자':'ds','구매수량':'y'}, inplace=True)\n",
    "customer1_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgiBc2_IdNP8"
   },
   "outputs": [],
   "source": [
    "customer1_time.set_index('ds').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNAAxE-ydNP8"
   },
   "outputs": [],
   "source": [
    "m = Prophet()\n",
    "m.fit(customer1_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIHzsG_rdNP9"
   },
   "outputs": [],
   "source": [
    "# make_future_dataframe() 함수를 이용해 예측값을 넣을 데이터 프레임을 생성\n",
    "# periods 값은 향후 몇일 (또는 주,월 등 단위 주기) 을 예측할 것인지를 의미 -> periods = 30 : 30일의 실적을 예측\n",
    "future = m.make_future_dataframe(periods=30)\n",
    "forecast = m.predict(future)\n",
    "fig1 = m.plot(forecast) # 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4NGXVzpdNP9"
   },
   "outputs": [],
   "source": [
    "# 피팅된 모델의 컴포넌트들을 시각화\n",
    "\n",
    "fig2 = m.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqnzrMVldNQB"
   },
   "outputs": [],
   "source": [
    "from prophet.plot import add_changepoints_to_plot\n",
    "\n",
    "m = Prophet(changepoint_prior_scale=0.05)\n",
    "m.fit(customer1_time)\n",
    "\n",
    "fig = m.plot(forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), m, forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4UKl6zVdNQB"
   },
   "outputs": [],
   "source": [
    "m = Prophet(changepoint_prior_scale=0.3)\n",
    "m.fit(customer1_time)\n",
    "\n",
    "fig = m.plot(forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), m, forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51sB6x7WfcEx"
   },
   "outputs": [],
   "source": [
    "m = Prophet(\n",
    "    # trend\n",
    "    changepoint_prior_scale=0.3,\n",
    "    # seasonality\n",
    "    weekly_seasonality=20,\n",
    "    daily_seasonality=False\n",
    ")\n",
    "\n",
    "m.fit(customer1_time)\n",
    "fig = m.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEmmQ7DXfnco"
   },
   "outputs": [],
   "source": [
    "m = Prophet(\n",
    "    # trend\n",
    "    changepoint_prior_scale=0.3,\n",
    "    # seasonality\n",
    "    weekly_seasonality=10,\n",
    "    daily_seasonality=10\n",
    ")\n",
    "\n",
    "m.fit(customer1_time)\n",
    "fig = m.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "syaKm8AdgDbp"
   },
   "outputs": [],
   "source": [
    "ms = Prophet(\n",
    "    # trend\n",
    "    changepoint_prior_scale=0.3,\n",
    "    # seasonality\n",
    "    weekly_seasonality=10,\n",
    "    daily_seasonality=10\n",
    ")\n",
    "\n",
    "ms.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "\n",
    "ms.fit(customer1_time)\n",
    "fig = ms.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TGFmIwKfgjnR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odJO7Ca7jCbc"
   },
   "source": [
    "### 3. train,test 나눠서 예측 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "byBo0QAXjHZB"
   },
   "outputs": [],
   "source": [
    "customer1_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8l490eFcjFlY"
   },
   "outputs": [],
   "source": [
    "train = customer1_time[:40]\n",
    "test = customer1_time[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wz__SWQbjzFd"
   },
   "outputs": [],
   "source": [
    "def utils_evaluate_forecast(dtf, title, plot=True, figsize=(20,13)):\n",
    "    try:\n",
    "        ## residuals\n",
    "        dtf[\"residuals\"] = dtf[\"ts\"] - dtf[\"model\"]\n",
    "        dtf[\"error\"] = dtf[\"ts\"] - dtf[\"forecast\"]\n",
    "        dtf[\"error_pct\"] = dtf[\"error\"] / dtf[\"ts\"]\n",
    "        \n",
    "        ## kpi\n",
    "        residuals_mean = dtf[\"residuals\"].mean()\n",
    "        residuals_std = dtf[\"residuals\"].std()\n",
    "        error_mean = dtf[\"error\"].mean()\n",
    "        error_std = dtf[\"error\"].std()\n",
    "        mae = dtf[\"error\"].apply(lambda x: np.abs(x)).mean()\n",
    "        mape = dtf[\"error_pct\"].apply(lambda x: np.abs(x)).mean()  \n",
    "        mse = dtf[\"error\"].apply(lambda x: x**2).mean()\n",
    "        rmse = np.sqrt(mse)  #root mean squared error\n",
    "        \n",
    "        ## intervals\n",
    "        dtf[\"conf_int_low\"] = dtf[\"forecast\"] - 1.96*residuals_std\n",
    "        dtf[\"conf_int_up\"] = dtf[\"forecast\"] + 1.96*residuals_std\n",
    "        dtf[\"pred_int_low\"] = dtf[\"forecast\"] - 1.96*error_std\n",
    "        dtf[\"pred_int_up\"] = dtf[\"forecast\"] + 1.96*error_std\n",
    "        \n",
    "        ## plot\n",
    "        if plot==True:\n",
    "            fig = plt.figure(figsize=figsize)\n",
    "            fig.suptitle(title, fontsize=20)   \n",
    "            ax1 = fig.add_subplot(2,2, 1)\n",
    "            ax2 = fig.add_subplot(2,2, 2, sharey=ax1)\n",
    "            ax3 = fig.add_subplot(2,2, 3)\n",
    "            ax4 = fig.add_subplot(2,2, 4)\n",
    "            ### training\n",
    "            dtf[pd.notnull(dtf[\"model\"])][[\"ts\",\"model\"]].plot(color=[\"black\",\"green\"], title=\"Model\", grid=True, ax=ax1)      \n",
    "            ax1.set(xlabel=None)\n",
    "            ### test\n",
    "            dtf[pd.isnull(dtf[\"model\"])][[\"ts\",\"forecast\"]].plot(color=[\"black\",\"red\"], title=\"Forecast\", grid=True, ax=ax2)\n",
    "            ax2.fill_between(x=dtf.index, y1=dtf['pred_int_low'], y2=dtf['pred_int_up'], color='b', alpha=0.2)\n",
    "            ax2.fill_between(x=dtf.index, y1=dtf['conf_int_low'], y2=dtf['conf_int_up'], color='b', alpha=0.3)     \n",
    "            ax2.set(xlabel=None)\n",
    "            ### residuals\n",
    "            dtf[[\"residuals\",\"error\"]].plot(ax=ax3, color=[\"green\",\"red\"], title=\"Residuals\", grid=True)\n",
    "            ax3.set(xlabel=None)\n",
    "            ### residuals distribution\n",
    "            dtf[[\"residuals\",\"error\"]].plot(ax=ax4, color=[\"green\",\"red\"], kind='kde', title=\"Residuals Distribution\", grid=True)\n",
    "            ax4.set(ylabel=None)\n",
    "            plt.show()\n",
    "            print(\"Training --> Residuals mean:\", np.round(residuals_mean), \" | std:\", np.round(residuals_std))\n",
    "            print(\"Test --> Error mean:\", np.round(error_mean), \" | std:\", np.round(error_std),\n",
    "                  \" | mae:\",np.round(mae), \" | mape:\",np.round(mape*100), \"%  | mse:\",np.round(mse), \" | rmse:\",np.round(rmse))\n",
    "        \n",
    "        return dtf[[\"ts\",\"model\",\"residuals\",\"conf_int_low\",\"conf_int_up\", \n",
    "                    \"forecast\",\"error\",\"pred_int_low\",\"pred_int_up\"]]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"--- got error ---\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vD5tia_TjfJq"
   },
   "outputs": [],
   "source": [
    "def fit_prophet(dtf_train, dtf_test, lst_exog=None, model=None, \n",
    "                freq=\"D\", figsize=(15,10)):\n",
    "    ## train\n",
    "    model.fit(dtf_train) ####\n",
    "    \n",
    "    ## test\n",
    "    dtf_prophet = model.make_future_dataframe(periods=len(dtf_test), \n",
    "                  freq=freq, include_history=True)\n",
    "    dtf_prophet = model.predict(dtf_prophet)\n",
    "    dtf_train = dtf_train.merge(dtf_prophet[[\"ds\",\"yhat\"]], \n",
    "                how=\"left\").rename(columns={'yhat':'model', \n",
    "                'y':'ts'}).set_index(\"ds\")\n",
    "    #dtf_test = dtf_test.merge(dtf_prophet[[\"ds\",\"yhat\"]], \n",
    "    #            how=\"left\").rename(columns={'yhat':'forecast',  \n",
    "    #            'y':'ts'}).set_index(\"ds\")\n",
    "    dtf_test = pd.DataFrame(dtf_prophet[[\"ds\",\"yhat\"]]['yhat'][40:])\n",
    "    dtf_test = pd.concat([test,dtf_test],axis=1)\n",
    "    dtf_test.set_index('ds',inplace=True)\n",
    "    dtf_test.rename(columns={'yhat':'forecast','y':'ts'},inplace=True)\n",
    "    \n",
    "    ## evaluate\n",
    "    dtf = dtf_train.append(dtf_test)\n",
    "    #dtf = pd.concat([dtf_train,dtf_test],axis=0)\n",
    "    dtf = utils_evaluate_forecast(dtf, figsize=figsize, \n",
    "                                  title=\"Prophet\")\n",
    "\n",
    "    return dtf, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7YJMZdcjVdp"
   },
   "outputs": [],
   "source": [
    "model = Prophet(growth=\"linear\", changepoints=None, \n",
    "                n_changepoints=25,\n",
    "                seasonality_mode=\"multiplicative\",\n",
    "                yearly_seasonality=True, \n",
    "                weekly_seasonality=\"auto\", \n",
    "                daily_seasonality=False,\n",
    "                holidays=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYtuKUVzjhT9"
   },
   "outputs": [],
   "source": [
    "dtf, model = fit_prophet(train, test, model=model, freq=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7obmVAHf_uJ"
   },
   "outputs": [],
   "source": [
    "model1 = Prophet(\n",
    "    # trend\n",
    "    changepoint_prior_scale=0.3,\n",
    "    # seasonality\n",
    "    weekly_seasonality=10,\n",
    "    daily_seasonality=10\n",
    ")\n",
    "\n",
    "dtf1, model1 = fit_prophet(train, test, model=model1, freq=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xuYGhn_l_1j"
   },
   "outputs": [],
   "source": [
    "model2 = Prophet(\n",
    "    # trend\n",
    "    changepoint_prior_scale=0.3,\n",
    "    # seasonality\n",
    "    weekly_seasonality=10,\n",
    "    daily_seasonality=10\n",
    ")\n",
    "\n",
    "model2.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "\n",
    "dtf2, model2 = fit_prophet(train, test, model=model2, freq=\"D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwBHI35nZD8_"
   },
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_7Kdzl5AEMc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('/content/gdrive/MyDrive/Project/lotte/data/products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9ed5f2b"
   },
   "outputs": [],
   "source": [
    "!pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXEHGy90MrsX"
   },
   "outputs": [],
   "source": [
    "!pip install scalecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DypCaM8QAimy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "mpl.rc('font', family='Malgun Gothic') # 폰트 설정\n",
    "mpl.rc('axes', unicode_minus=False) # 유니코드에서 음수 부호 설정\n",
    "\n",
    "# 차트 스타일 설정\n",
    "sns.set(font=\"Malgun Gothic\", rc={\"axes.unicode_minus\":False}, style='darkgrid')\n",
    "plt.rc(\"figure\", figsize=(10,8))\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRG2Ocm9HGXa"
   },
   "source": [
    "### CLTV 값 있는 고객만 골라내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCOWKDgjA9yr"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/gdrive/MyDrive/Project/lotte/data/products.csv')\n",
    "df.rename(columns={'대분류명':'중분류명','중분류명':'대분류명'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mi6bxzWBiGe"
   },
   "outputs": [],
   "source": [
    "cltv = pd.read_csv('/content/gdrive/MyDrive/Project/lotte/data/final_cltv.csv')\n",
    "cltv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUkcNiDoBtRt"
   },
   "outputs": [],
   "source": [
    "cltv_client = cltv['고객번호'].unique().tolist()\n",
    "df['고객번호'] = df['고객번호'].apply(lambda x : x if x in cltv_client else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6lv1R1UCgUC"
   },
   "outputs": [],
   "source": [
    "df = df[df['고객번호']!=0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFIGumFSHODg"
   },
   "outputs": [],
   "source": [
    "df.to_csv('/content/gdrive/MyDrive/Project/lotte/data/products_cltv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcQQHJx8KvsF"
   },
   "source": [
    "### 대상 고객, 상품 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYs0DoQqK1cd"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/gdrive/MyDrive/Project/lotte/data/products_cltv.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pgUdec16_xO"
   },
   "source": [
    "M057015266 고객의 건강용품 구매수량 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xN1-DFEjZcot"
   },
   "outputs": [],
   "source": [
    "df['고객번호'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eoX_zs_4Zcou"
   },
   "outputs": [],
   "source": [
    "df[df['고객번호']=='M057015266']['대분류명'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_os8iDDZcou"
   },
   "outputs": [],
   "source": [
    "id= 'M057015266'\n",
    "product = '과자'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "720b6d24"
   },
   "outputs": [],
   "source": [
    "data = df[(df['고객번호']==id) & (df['대분류명']==product)]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99e4d7d0"
   },
   "outputs": [],
   "source": [
    "data['구매일자'] = data['구매일자'].astype('str')\n",
    "data['구매일자'] = pd.to_datetime(data['구매일자'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1e89dc6e"
   },
   "outputs": [],
   "source": [
    "data = data.groupby('구매일자')[['구매수량']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_K2E2jZZcov"
   },
   "outputs": [],
   "source": [
    "# 중간 날짜 데이터 채우기\n",
    "data_index_list = data.index.tolist()\n",
    "for i in range(len(data_index_list)-1) : \n",
    "    start_date = pd.to_datetime(str(data_index_list[i])[:10]) ## 시작 날짜\n",
    "    end_date = pd.to_datetime(str(data_index_list[i+1])[:10]) ## 마지막 날짜\n",
    "    dates = pd.date_range(start_date,end_date,freq='D') ## 일단위로 생성\n",
    "    \n",
    "    tt = pd.DataFrame(index = dates, columns = data.columns)\n",
    "    tt = tt.fillna(0)\n",
    "    tt = tt[1:-1]\n",
    "    data = pd.concat([data, tt], axis = 0)\n",
    "    data = data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHdiQ1qlZcow"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2LJ1wgpZcoy"
   },
   "outputs": [],
   "source": [
    "DATE = data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c604b5d6"
   },
   "source": [
    "### ARIMA 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9cbe227"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scalecast.Forecaster import Forecaster\n",
    "from scalecast import GridGenerator\n",
    "from pmdarima import auto_arima\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(14,7)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyIW36dkEqrG"
   },
   "source": [
    "##### 원본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f83e7aab"
   },
   "outputs": [],
   "source": [
    "# f = Forecaster(y=data['구매수량'],current_dates=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9e6cdc13"
   },
   "outputs": [],
   "source": [
    "# f.generate_future_dates(12) # 12-month forecast horizon\n",
    "# f.set_test_length(.2) # 20% test set\n",
    "# f.set_estimator('arima') # set arima\n",
    "# f.manual_forecast(call_me='arima1') # forecast with arima\n",
    "\n",
    "# f.plot_test_set(ci=True) # view test results\n",
    "# plt.title('ARIMA Test-Set Performance',size=14)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8f9f398",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # EDA\n",
    "# f.plot_acf()\n",
    "# plt.show()\n",
    "# f.plot_pacf()\n",
    "# plt.show()\n",
    "# f.seasonal_decompose().plot()\n",
    "# plt.show()\n",
    "# stat, pval, _, _, _, _ = f.adf_test(full_res=True)\n",
    "# print(stat)\n",
    "# print(pval)\n",
    "\n",
    "# # Forecast\n",
    "# f.manual_forecast(order=(1,1,1),seasonal_order=(2,1,1,12),call_me='arima2')\n",
    "\n",
    "# # View test results\n",
    "# f.plot_test_set(ci=True,models='arima2')\n",
    "# plt.title('ARIMA Test-Set Performance',size=14)\n",
    "# plt.show()\n",
    "\n",
    "# # View forecast results\n",
    "# f.plot(ci=True,models='arima2')\n",
    "# plt.title('ARIMA Forecast Performance',size=14)\n",
    "# plt.show()\n",
    "\n",
    "# # See summary stats\n",
    "# f.regr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UmZxJE5E0ZP"
   },
   "source": [
    "##### MinMaxScaler_사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6Wp4RlJDE8H"
   },
   "outputs": [],
   "source": [
    "def MinMaxScaler_(x) : \n",
    "  x_MinMax = (x - x.min(axis=0)) / (x.max(axis=0) - x.min(axis=0))\n",
    "  return x_MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6fe525c"
   },
   "outputs": [],
   "source": [
    "## 정상성을 해결하기 위한 1차 차분\n",
    "## minmaxscale\n",
    "import numpy\n",
    "x = data['구매수량'].values\n",
    "x_scaled = MinMaxScaler_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iEDp7s2oGFyM"
   },
   "outputs": [],
   "source": [
    "min_value = x.min(axis = 0)\n",
    "max_value = x.max(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68fdb9a7"
   },
   "outputs": [],
   "source": [
    "f = Forecaster(y=x_scaled, current_dates=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26cd1608"
   },
   "outputs": [],
   "source": [
    "f.generate_future_dates(12) # 12-month forecast horizon\n",
    "f.set_test_length(.2) # 20% test set\n",
    "f.set_estimator('arima') # set arima\n",
    "f.manual_forecast(call_me='arima1') # forecast with arima\n",
    "\n",
    "f.plot_test_set(ci=True) # view test results\n",
    "plt.title('ARIMA Test-Set Performance',size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ws4HvD_Mchb9"
   },
   "source": [
    "* ACF : 자기상관함수(Autocorrelation Fucntion)\n",
    "  * y(t)와 y(t+k) 사이에 correlation을 측정\n",
    "  * 이 값이 가장 작은 모델 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "610630f7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# EDA\n",
    "f.plot_acf()\n",
    "plt.show()\n",
    "f.plot_pacf()\n",
    "plt.show()\n",
    "f.seasonal_decompose().plot()\n",
    "plt.show()\n",
    "stat, pval, _, _, _, _ = f.adf_test(full_res=True)\n",
    "print(stat)\n",
    "print(pval)\n",
    "\n",
    "# Forecast\n",
    "f.manual_forecast(order=(1,1,1),seasonal_order=(2,1,1,12),call_me='arima2')\n",
    "\n",
    "# View test results\n",
    "f.plot_test_set(ci=True,models='arima2')\n",
    "plt.title('ARIMA Test-Set Performance',size=14)\n",
    "plt.show()\n",
    "\n",
    "# View forecast results\n",
    "f.plot(ci=True,models='arima2')\n",
    "plt.title('ARIMA Forecast Performance',size=14)\n",
    "plt.show()\n",
    "\n",
    "# See summary stats\n",
    "f.regr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKHj2emJ7Tgg"
   },
   "source": [
    "#### 공통"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d87dc4c0"
   },
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train = data.iloc[:int(.8*(data.shape[0])),-1]\n",
    "auto_model = auto_arima(\n",
    "  train,\n",
    "  start_P=1,\n",
    "  start_q=1,\n",
    "  max_p=6,\n",
    "  max_q=6,m=12,\n",
    "  seasonal=True,\n",
    "  max_P=2, \n",
    "  max_D=2,\n",
    "  max_Q=2,\n",
    "  max_d=2,\n",
    "  trace=True,\n",
    "  error_action='ignore',\n",
    "  suppress_warnings=True,\n",
    "  stepwise=True,\n",
    "  information_criterion=\"aic\",\n",
    "  alpha=0.05,\n",
    "  scoring='mse'\n",
    ")\n",
    "\n",
    "best_params = auto_model.get_params()\n",
    "order = best_params['order']\n",
    "seasonal_order = best_params['seasonal_order']\n",
    "trend = best_params['trend']\n",
    "\n",
    "f.manual_forecast(order=order,seasonal_order=seasonal_order,trend=trend,call_me='arima3')\n",
    "\n",
    "f.plot_test_set(ci=True,models='arima3')\n",
    "plt.title('ARIMA Test-Set Performance',size=14)\n",
    "plt.show()\n",
    "\n",
    "f.plot(ci=True,models='arima3')\n",
    "plt.title('ARIMA Forecast Performance',size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "440b750a"
   },
   "outputs": [],
   "source": [
    "f.regr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1d508dbf"
   },
   "outputs": [],
   "source": [
    "f.set_validation_length(12)\n",
    "grid = {\n",
    "    'order':[(1,1,1),(1,1,0),(0,1,1),(0,0,1),(6,0,4), (6,1,1), (0,0,0)],\n",
    "    'seasonal_order':[(2,1,1,12),(1,1,1,12),(2,1,0,12),(0,1,0,12)]\n",
    "}\n",
    "\n",
    "f.ingest_grid(grid)\n",
    "f.tune()\n",
    "f.auto_forecast(call_me='arima3')\n",
    "\n",
    "f.plot_test_set(ci=True,models='arima3')\n",
    "plt.title('ARIMA Test-Set Performance',size=14)\n",
    "plt.show()\n",
    "\n",
    "f.plot(ci=True,models='arima3')\n",
    "plt.title('ARIMA Forecast Performance',size=14)\n",
    "plt.show()\n",
    "\n",
    "f.regr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ad112d0"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100\n",
    "results = f.export(to_excel=False,\n",
    "                   excel_name='/content/gdrive/MyDrive/Project/lotte/data/{}_{}_performance.xlsx'.format(id,product),\n",
    "                   determine_best_by='TestSetMAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0e2c34df"
   },
   "outputs": [],
   "source": [
    "summaries = results['model_summaries']\n",
    "summaries.to_csv('/content/gdrive/MyDrive/Project/lotte/data/{}_{}_performance.csv'.format(id,product))\n",
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zI_t4WfsHCl"
   },
   "outputs": [],
   "source": [
    "summaries.iloc[:,10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "161e642f"
   },
   "outputs": [],
   "source": [
    "f.export(cis = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWVLBEpQ-nw6"
   },
   "outputs": [],
   "source": [
    "f.export()['test_set_predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8c0141b5"
   },
   "outputs": [],
   "source": [
    "dates = f.export()['test_set_predictions']['DATE']\n",
    "real = f.export()['test_set_predictions']['actual']\n",
    "pred = f.export()['test_set_predictions']['arima3']\n",
    "pred_upper = f.export(cis = True)['test_set_predictions']['arima3_upperci']\n",
    "pred_lower = f.export(cis = True)['test_set_predictions']['arima3_lowerci']\n",
    "future_dates =  f.export()['all_fcsts']['DATE']\n",
    "future = f.export()['all_fcsts']['arima3']\n",
    "future_upper = f.export(cis = True)['all_fcsts']['arima3_upperci']\n",
    "future_lower = f.export(cis = True)['all_fcsts']['arima3_lowerci']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSuTR5Tj20Yj"
   },
   "outputs": [],
   "source": [
    "def MinMax_to_Raw(x_MinMax, min_value, max_value) : \n",
    "  x = map(int, x_MinMax * (max_value - min_value) +  min_value)\n",
    "  return list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3TdWk7MS24az"
   },
   "outputs": [],
   "source": [
    "raw_data = pd.DataFrame(MinMax_to_Raw(real, min_value, max_value), index = dates)\n",
    "pred_data = pd.DataFrame(MinMax_to_Raw(pred, min_value, max_value), index = dates)\n",
    "pred_upper_data = pd.DataFrame(MinMax_to_Raw(pred_upper, min_value, max_value), index = dates)\n",
    "pred_lower_data = pd.DataFrame(MinMax_to_Raw(pred_lower, min_value, max_value), index = dates)\n",
    "future_data = pd.DataFrame(MinMax_to_Raw(future, min_value, max_value), index = future_dates)\n",
    "future_upper_data = pd.DataFrame(MinMax_to_Raw(future_upper, min_value, max_value), index = future_dates)\n",
    "future_lower_data = pd.DataFrame(MinMax_to_Raw(future_lower, min_value, max_value), index = future_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixDAqxafCVpi"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "dataset = pd.DataFrame(index = pd.date_range(data.index[0],future_dates[11],freq='D'), columns = ['raw','predicted','predicted_upperci','predicted_lowerci'])\n",
    "dataset.loc[data.index, 'raw'] = data['구매수량']\n",
    "dataset.loc[pred_data.index, 'predicted'] = pred_data[0].tolist()\n",
    "dataset.loc[future_data.index, 'predicted'] = future_data[0].tolist()\n",
    "dataset.loc[pred_upper_data.index, 'predicted_upperci'] = pred_upper_data[0].tolist()\n",
    "dataset.loc[future_upper_data.index, 'predicted_upperci'] = future_upper_data[0].tolist()\n",
    "dataset.loc[pred_lower_data.index, 'predicted_lowerci'] = pred_lower_data[0].tolist()\n",
    "dataset.loc[future_lower_data.index, 'predicted_lowerci'] = future_lower_data[0].tolist()\n",
    "dataset['predicted_upperci'] = dataset['predicted_upperci'].apply(lambda x : 0 if x<0 else x)\n",
    "dataset['predicted_lowerci'] = dataset['predicted_lowerci'].apply(lambda x : 0 if x<0 else x)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Yqug9LU0tTs"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25, 8))\n",
    "plt.rc('xtick', labelsize=15)  # x축 눈금 폰트 크기 \n",
    "plt.rc('ytick', labelsize=20)  # y축 눈금 폰트 크기\n",
    "plt.rc('legend', fontsize=20)  # 범례 폰트 크기\n",
    "plt.plot(dataset['raw'], label = 'raw')\n",
    "plt.plot(dataset['predicted'], label = 'predicted')\n",
    "plt.fill_between(dataset[dataset.index>=dates.iloc[0]].index, dataset.loc[dataset.index>=dates.iloc[0],'predicted_lowerci'].tolist(), dataset.loc[dataset.index>=dates.iloc[0],'predicted_upperci'].tolist(), color = 'orange', alpha = 0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('/content/gdrive/MyDrive/Project/lotte/data/{} 고객의 {} 구매수량 예측'.format(id,product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KNmSXohSHYfY"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 8))\n",
    "plt.rc('xtick', labelsize=15)  # x축 눈금 폰트 크기 \n",
    "plt.rc('ytick', labelsize=20)  # y축 눈금 폰트 크기\n",
    "plt.rc('legend', fontsize=20)  # 범례 폰트 크기\n",
    "plt.plot(dataset.loc[dataset.index>dates.iloc[0],'raw'], label = 'raw')\n",
    "plt.plot(dataset['predicted'], label = 'predicted')\n",
    "plt.fill_between(dataset[dataset.index>=dates.iloc[0]].index, dataset.loc[dataset.index>=dates.iloc[0],'predicted_lowerci'].tolist(), dataset.loc[dataset.index>=dates.iloc[0],'predicted_upperci'].tolist(), color = 'orange', alpha = 0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('/content/gdrive/MyDrive/Project/lotte/data/{} 고객의 {} 구매수량 예측(예측범위만)'.format(id,product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CeOlTmde6kmS"
   },
   "outputs": [],
   "source": [
    "dataset.to_csv('/content/gdrive/MyDrive/Project/lotte/data/{}_{}_raw_predict_values.csv'.format(id,product))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czA6scdJI-ix"
   },
   "source": [
    "### ARIMA 자동화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vnn1bE36Kucy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from scalecast.Forecaster import Forecaster\n",
    "from scalecast import GridGenerator\n",
    "from pmdarima import auto_arima\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(14,7)})\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qi9848cGJIYx"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/gdrive/MyDrive/Project/lotte/data/products_cltv.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0fkt-WBKzBU"
   },
   "outputs": [],
   "source": [
    "def MinMaxScaler_(x) : \n",
    "  x_MinMax = (x - x.min(axis=0)) / (x.max(axis=0) - x.min(axis=0))\n",
    "  return x_MinMax\n",
    "\n",
    "def MinMax_to_Raw(x_MinMax, min_value, max_value) : \n",
    "  x = map(int, x_MinMax * (max_value - min_value) +  min_value)\n",
    "  return list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4GMPFhiiMKdu"
   },
   "outputs": [],
   "source": [
    "# 고객리스트\n",
    "clients = ['M057015266', 'M124357021', 'M282063613','M576689847', 'M596502154', 'M378415176','M408936009', 'M652598612', 'M865603201']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZfCWyIgsJNz7"
   },
   "outputs": [],
   "source": [
    "for i in range(len(clients)) : \n",
    "  id= clients[i]\n",
    "  product = df[df['고객번호']==clients[i]]['대분류명'].value_counts().index[0]\n",
    "  print(id,':',product)\n",
    "  data = df[(df['고객번호']==id) & (df['대분류명']==product)]\n",
    "  data['구매일자'] = data['구매일자'].astype('str')\n",
    "  data['구매일자'] = pd.to_datetime(data['구매일자'])\n",
    "  data = data.groupby('구매일자')[['구매수량']].sum()\n",
    "\n",
    "  # 중간 날짜 데이터 채우기\n",
    "  data_index_list = data.index.tolist()\n",
    "  for i in range(len(data_index_list)-1) : \n",
    "      start_date = pd.to_datetime(str(data_index_list[i])[:10]) ## 시작 날짜\n",
    "      end_date = pd.to_datetime(str(data_index_list[i+1])[:10]) ## 마지막 날짜\n",
    "      dates = pd.date_range(start_date,end_date,freq='D') ## 일단위로 생성\n",
    "      \n",
    "      tt = pd.DataFrame(index = dates, columns = data.columns)\n",
    "      tt = tt.fillna(0)\n",
    "      tt = tt[1:-1]\n",
    "      data = pd.concat([data, tt], axis = 0)\n",
    "      data = data.sort_index()\n",
    "\n",
    "  x = data['구매수량'].values\n",
    "  x_scaled = MinMaxScaler_(x)\n",
    "  min_value = x.min(axis = 0)\n",
    "  max_value = x.max(axis = 0)\n",
    "\n",
    "  f = Forecaster(y=x_scaled, current_dates=data.index)\n",
    "\n",
    "  f.generate_future_dates(12) # 12-month forecast horizon\n",
    "  f.set_test_length(.2) # 20% test set\n",
    "  f.set_estimator('arima') # set arima\n",
    "  f.manual_forecast(call_me='arima1') # forecast with arima\n",
    "\n",
    "  f.manual_forecast(order=(1,1,1),seasonal_order=(2,1,1,12),call_me='arima2')\n",
    "\n",
    "  train = data.iloc[:int(.8*(data.shape[0])),-1]\n",
    "  auto_model = auto_arima(\n",
    "    train,\n",
    "    start_P=1,\n",
    "    start_q=1,\n",
    "    max_p=6,\n",
    "    max_q=6,m=12,\n",
    "    seasonal=True,\n",
    "    max_P=2, \n",
    "    max_D=2,\n",
    "    max_Q=2,\n",
    "    max_d=2,\n",
    "    trace=True,\n",
    "    error_action='ignore',\n",
    "    suppress_warnings=True,\n",
    "    stepwise=True,\n",
    "    information_criterion=\"aic\",\n",
    "    alpha=0.05,\n",
    "    scoring='mse'\n",
    "  )\n",
    "\n",
    "  best_params = auto_model.get_params()\n",
    "  order = best_params['order']\n",
    "  seasonal_order = best_params['seasonal_order']\n",
    "  trend = best_params['trend']\n",
    "\n",
    "  f.manual_forecast(order=order,seasonal_order=seasonal_order,trend=trend,call_me='arima3')\n",
    "  f.set_validation_length(12)\n",
    "  grid = {\n",
    "      'order':[(1,1,1),(1,1,0),(0,1,1),(0,0,1),(6,0,4), (6,1,1), (0,0,0)],\n",
    "      'seasonal_order':[(2,1,1,12),(1,1,1,12),(2,1,0,12),(0,1,0,12)]\n",
    "  }\n",
    "  f.ingest_grid(grid)\n",
    "  f.tune()\n",
    "  f.auto_forecast(call_me='arima3')\n",
    "\n",
    "  pd.options.display.max_colwidth = 100\n",
    "  results = f.export(to_excel=False,\n",
    "                    excel_name='/content/gdrive/MyDrive/Project/lotte/data/{}_{}_performance.xlsx'.format(id,product),\n",
    "                    determine_best_by='TestSetMAPE')\n",
    "  summaries = results['model_summaries']\n",
    "  summaries.to_csv('/content/gdrive/MyDrive/Project/lotte/data/{}_{}_performance.csv'.format(id,product))\n",
    "\n",
    "  dates = f.export()['test_set_predictions']['DATE']\n",
    "  real = f.export()['test_set_predictions']['actual']\n",
    "  pred = f.export()['test_set_predictions']['arima3']\n",
    "  pred_upper = f.export(cis = True)['test_set_predictions']['arima3_upperci']\n",
    "  pred_lower = f.export(cis = True)['test_set_predictions']['arima3_lowerci']\n",
    "  future_dates =  f.export()['all_fcsts']['DATE']\n",
    "  future = f.export()['all_fcsts']['arima3']\n",
    "  future_upper = f.export(cis = True)['all_fcsts']['arima3_upperci']\n",
    "  future_lower = f.export(cis = True)['all_fcsts']['arima3_lowerci']\n",
    "\n",
    "  raw_data = pd.DataFrame(MinMax_to_Raw(real, min_value, max_value), index = dates)\n",
    "  pred_data = pd.DataFrame(MinMax_to_Raw(pred, min_value, max_value), index = dates)\n",
    "  pred_upper_data = pd.DataFrame(MinMax_to_Raw(pred_upper, min_value, max_value), index = dates)\n",
    "  pred_lower_data = pd.DataFrame(MinMax_to_Raw(pred_lower, min_value, max_value), index = dates)\n",
    "  future_data = pd.DataFrame(MinMax_to_Raw(future, min_value, max_value), index = future_dates)\n",
    "  future_upper_data = pd.DataFrame(MinMax_to_Raw(future_upper, min_value, max_value), index = future_dates)\n",
    "  future_lower_data = pd.DataFrame(MinMax_to_Raw(future_lower, min_value, max_value), index = future_dates)\n",
    "\n",
    "  dataset = pd.DataFrame(index = pd.date_range(data.index[0],future_dates[11],freq='D'), columns = ['raw','predicted','predicted_upperci','predicted_lowerci'])\n",
    "  dataset.loc[data.index, 'raw'] = data['구매수량']\n",
    "  dataset.loc[pred_data.index, 'predicted'] = pred_data[0].tolist()\n",
    "  dataset.loc[future_data.index, 'predicted'] = future_data[0].tolist()\n",
    "  dataset.loc[pred_upper_data.index, 'predicted_upperci'] = pred_upper_data[0].tolist()\n",
    "  dataset.loc[future_upper_data.index, 'predicted_upperci'] = future_upper_data[0].tolist()\n",
    "  dataset.loc[pred_lower_data.index, 'predicted_lowerci'] = pred_lower_data[0].tolist()\n",
    "  dataset.loc[future_lower_data.index, 'predicted_lowerci'] = future_lower_data[0].tolist()\n",
    "  dataset['predicted_upperci'] = dataset['predicted_upperci'].apply(lambda x : 0 if x<0 else x)\n",
    "  dataset['predicted_lowerci'] = dataset['predicted_lowerci'].apply(lambda x : 0 if x<0 else x)\n",
    "\n",
    "  plt.figure(figsize = (25, 8))\n",
    "  plt.rc('xtick', labelsize=15)  # x축 눈금 폰트 크기 \n",
    "  plt.rc('ytick', labelsize=20)  # y축 눈금 폰트 크기\n",
    "  plt.rc('legend', fontsize=20)  # 범례 폰트 크기\n",
    "  plt.plot(dataset['raw'], label = 'raw')\n",
    "  plt.plot(dataset['predicted'], label = 'predicted')\n",
    "  plt.fill_between(dataset[dataset.index>=dates.iloc[0]].index, dataset.loc[dataset.index>=dates.iloc[0],'predicted_lowerci'].tolist(), dataset.loc[dataset.index>=dates.iloc[0],'predicted_upperci'].tolist(), color = 'orange', alpha = 0.3)\n",
    "  plt.legend()\n",
    "  plt.savefig('/content/gdrive/MyDrive/Project/lotte/data/{} 고객의 {} 구매수량 예측'.format(id,product))\n",
    "\n",
    "  plt.figure(figsize = (20, 8))\n",
    "  plt.rc('xtick', labelsize=15)  # x축 눈금 폰트 크기 \n",
    "  plt.rc('ytick', labelsize=20)  # y축 눈금 폰트 크기\n",
    "  plt.rc('legend', fontsize=20)  # 범례 폰트 크기\n",
    "  plt.plot(dataset.loc[dataset.index>dates.iloc[0],'raw'], label = 'raw')\n",
    "  plt.plot(dataset['predicted'], label = 'predicted')\n",
    "  plt.fill_between(dataset[dataset.index>=dates.iloc[0]].index, dataset.loc[dataset.index>=dates.iloc[0],'predicted_lowerci'].tolist(), dataset.loc[dataset.index>=dates.iloc[0],'predicted_upperci'].tolist(), color = 'orange', alpha = 0.3)\n",
    "  plt.legend()\n",
    "  plt.savefig('/content/gdrive/MyDrive/Project/lotte/data/{} 고객의 {} 구매수량 예측(예측범위만)'.format(id,product))\n",
    "\n",
    "  dataset.to_csv('/content/gdrive/MyDrive/Project/lotte/data/{}_{}_raw_predict_values.csv'.format(id,product))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMW+A1Hzam2GMomRrvQm1fd",
   "collapsed_sections": [
    "vilD19QJUqed",
    "5e298dfb",
    "NcC-eQZGVBYJ",
    "vzrP82VSPdqu",
    "Kyl6SRKhPkb_",
    "UUrVEVp5PpoX",
    "cJ6b7tUCVexQ",
    "3cRDLNTaWH2E",
    "7b6d2bf6",
    "E8774dx5XBl5",
    "SMjQMvTZXG2G",
    "lWDHPCQbYPY1",
    "IRz9Mvq9Yl6K",
    "da86a44b",
    "KkPgnouHYSZ0",
    "1cHVsmY1yMJI",
    "9MHhORvXyMJK",
    "32Vv79nyXrN7",
    "SkCisOpzdINQ",
    "Q5RNOZFAVzxl",
    "_2nvJWbGYnGP",
    "DQvesxc-dNP5",
    "e7ZCJCBTfPMT",
    "odJO7Ca7jCbc",
    "KwBHI35nZD8_",
    "hRG2Ocm9HGXa",
    "hcQQHJx8KvsF",
    "c604b5d6",
    "QyIW36dkEqrG",
    "8UmZxJE5E0ZP",
    "eKHj2emJ7Tgg",
    "czA6scdJI-ix"
   ],
   "name": "최종.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
